"""
æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ
è‡ªåŠ¨è¯†åˆ«å’Œä¼˜åŒ–è®¡ç®—å¯†é›†å‹å‡½æ•°çš„ç¼“å­˜ç­–ç•¥
"""

import streamlit as st
import functools
import hashlib
import json
import time
from typing import Callable, Any, Optional, Dict, Tuple
import numpy as np


class CacheConfig:
    """ç¼“å­˜é…ç½®"""
    
    # ä¸åŒç±»å‹è®¡ç®—çš„é»˜è®¤TTLï¼ˆç§’ï¼‰
    TTL_CONFIGS = {
        'fast': 300,        # 5åˆ†é’Ÿ - å¿«é€Ÿè®¡ç®—
        'medium': 1800,     # 30åˆ†é’Ÿ - ä¸­ç­‰è®¡ç®—
        'heavy': 3600,      # 1å°æ—¶ - é‡å‹è®¡ç®—
        'static': None,     # æ°¸ä¹… - é™æ€æ•°æ®
    }
    
    # è‡ªåŠ¨æ£€æµ‹è®¡ç®—ç±»å‹çš„é˜ˆå€¼ï¼ˆç§’ï¼‰
    TIMING_THRESHOLDS = {
        'fast': 0.1,
        'medium': 1.0,
        'heavy': 5.0,
    }


class SmartCache:
    """æ™ºèƒ½ç¼“å­˜è£…é¥°å™¨"""
    
    def __init__(
        self,
        ttl: Optional[int] = None,
        cache_type: str = 'auto',
        show_stats: bool = False,
        max_entries: Optional[int] = None
    ):
        """
        åˆå§‹åŒ–æ™ºèƒ½ç¼“å­˜
        
        Args:
            ttl: ç¼“å­˜ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNoneè¡¨ç¤ºæ°¸ä¹…
            cache_type: ç¼“å­˜ç±»å‹ ('auto', 'fast', 'medium', 'heavy', 'static')
            show_stats: æ˜¯å¦æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
            max_entries: æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
        """
        self.ttl = ttl
        self.cache_type = cache_type
        self.show_stats = show_stats
        self.max_entries = max_entries
        self._execution_times = []
    
    def __call__(self, func: Callable) -> Callable:
        """è£…é¥°å™¨è°ƒç”¨"""
        
        # å¦‚æœæ˜¯autoæ¨¡å¼ï¼Œå…ˆæµ‹é‡å‡ æ¬¡æ‰§è¡Œæ—¶é—´
        if self.cache_type == 'auto':
            actual_ttl = CacheConfig.TTL_CONFIGS['medium']  # é»˜è®¤
        else:
            actual_ttl = self.ttl or CacheConfig.TTL_CONFIGS.get(self.cache_type)
        
        # ä½¿ç”¨streamlitçš„ç¼“å­˜
        @st.cache_data(ttl=actual_ttl, show_spinner=False)
        def cached_wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            elapsed = time.time() - start_time
            
            # è®°å½•æ‰§è¡Œæ—¶é—´ç”¨äºè‡ªé€‚åº”è°ƒæ•´
            self._execution_times.append(elapsed)
            
            return result, elapsed
        
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            result, elapsed = cached_wrapper(*args, **kwargs)
            
            # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
            if self.show_stats:
                cache_info = self._get_cache_info(func.__name__, elapsed)
                st.caption(cache_info)
            
            return result
        
        return wrapper
    
    def _get_cache_info(self, func_name: str, elapsed: float) -> str:
        """è·å–ç¼“å­˜ä¿¡æ¯"""
        avg_time = sum(self._execution_times) / len(self._execution_times)
        return f"âš¡ {func_name}: {elapsed*1000:.0f}ms (å¹³å‡: {avg_time*1000:.0f}ms)"


def auto_cache(func: Callable) -> Callable:
    """
    è‡ªåŠ¨ç¼“å­˜è£…é¥°å™¨ - æ ¹æ®ç¬¬ä¸€æ¬¡æ‰§è¡Œæ—¶é—´è‡ªåŠ¨é€‰æ‹©TTL
    
    ä½¿ç”¨æ–¹æ³•ï¼š
    @auto_cache
    def expensive_computation(x, y):
        return heavy_calculation(x, y)
    """
    execution_count = {'count': 0, 'total_time': 0.0}
    
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        execution_count['count'] += 1
        
        # ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼Œæµ‹é‡æ—¶é—´
        if execution_count['count'] == 1:
            start = time.time()
            result = func(*args, **kwargs)
            elapsed = time.time() - start
            execution_count['total_time'] = elapsed
            
            # æ ¹æ®æ‰§è¡Œæ—¶é—´é€‰æ‹©TTL
            if elapsed < CacheConfig.TIMING_THRESHOLDS['fast']:
                ttl = CacheConfig.TTL_CONFIGS['fast']
                cache_type = "å¿«é€Ÿ"
            elif elapsed < CacheConfig.TIMING_THRESHOLDS['medium']:
                ttl = CacheConfig.TTL_CONFIGS['medium']
                cache_type = "ä¸­ç­‰"
            elif elapsed < CacheConfig.TIMING_THRESHOLDS['heavy']:
                ttl = CacheConfig.TTL_CONFIGS['heavy']
                cache_type = "é‡å‹"
            else:
                ttl = CacheConfig.TTL_CONFIGS['static']
                cache_type = "è¶…é‡"
            
            # åˆ›å»ºç¼“å­˜ç‰ˆæœ¬
            @st.cache_data(ttl=ttl)
            def cached_func(*args, **kwargs):
                return func(*args, **kwargs)
            
            # ä¿å­˜ç¼“å­˜å‡½æ•°ä¾›åç»­ä½¿ç”¨
            wrapper._cached_func = cached_func
            wrapper._cache_type = cache_type
            wrapper._ttl = ttl
            
            return result
        else:
            # åç»­è°ƒç”¨ä½¿ç”¨ç¼“å­˜
            if hasattr(wrapper, '_cached_func'):
                return wrapper._cached_func(*args, **kwargs)
            else:
                return func(*args, **kwargs)
    
    return wrapper


def cache_numpy_computation(ttl: int = 1800):
    """
    ä¸“é—¨ç”¨äºNumPyè®¡ç®—çš„ç¼“å­˜è£…é¥°å™¨
    è‡ªåŠ¨å¤„ç†NumPyæ•°ç»„çš„å“ˆå¸Œ
    
    ä½¿ç”¨æ–¹æ³•ï¼š
    @cache_numpy_computation(ttl=3600)
    def matrix_multiply(A, B):
        return np.dot(A, B)
    """
    def decorator(func: Callable) -> Callable:
        @st.cache_data(ttl=ttl)
        def wrapper(*args, **kwargs):
            # å°†NumPyæ•°ç»„è½¬æ¢ä¸ºå¯å“ˆå¸Œçš„æ ¼å¼
            hashable_args = []
            for arg in args:
                if isinstance(arg, np.ndarray):
                    # ä½¿ç”¨æ•°ç»„çš„å½¢çŠ¶ã€dtypeå’Œéƒ¨åˆ†æ•°æ®ç”Ÿæˆå“ˆå¸Œ
                    hashable_args.append((arg.shape, arg.dtype.name, arg.tobytes()[:1000]))
                else:
                    hashable_args.append(arg)
            
            hashable_kwargs = {}
            for k, v in kwargs.items():
                if isinstance(v, np.ndarray):
                    hashable_kwargs[k] = (v.shape, v.dtype.name, v.tobytes()[:1000])
                else:
                    hashable_kwargs[k] = v
            
            return func(*args, **kwargs)
        
        return wrapper
    return decorator


class ProgressiveCache:
    """
    æ¸è¿›å¼ç¼“å­˜ - å¯¹äºå¤§å‹è®¡ç®—ï¼Œåˆ†é˜¶æ®µç¼“å­˜ä¸­é—´ç»“æœ
    """
    
    def __init__(self, stages: list):
        """
        Args:
            stages: é˜¶æ®µåç§°åˆ—è¡¨ï¼Œå¦‚ ['preprocess', 'compute', 'postprocess']
        """
        self.stages = stages
        self.cache_keys = {stage: f"progressive_cache_{stage}" for stage in stages}
    
    def cache_stage(self, stage: str):
        """ç¼“å­˜æŸä¸ªé˜¶æ®µçš„è£…é¥°å™¨"""
        if stage not in self.stages:
            raise ValueError(f"Unknown stage: {stage}")
        
        def decorator(func: Callable) -> Callable:
            @st.cache_data(ttl=3600)
            def wrapper(*args, **kwargs):
                return func(*args, **kwargs)
            return wrapper
        return decorator


class AdaptiveCache:
    """
    è‡ªé€‚åº”ç¼“å­˜ - æ ¹æ®å‚æ•°å¤æ‚åº¦åŠ¨æ€è°ƒæ•´TTL
    """
    
    @staticmethod
    def calculate_complexity(args, kwargs) -> float:
        """è®¡ç®—å‚æ•°å¤æ‚åº¦åˆ†æ•°"""
        complexity = 0
        
        for arg in args:
            if isinstance(arg, (list, tuple)):
                complexity += len(arg)
            elif isinstance(arg, np.ndarray):
                complexity += arg.size
            elif isinstance(arg, (int, float)):
                complexity += abs(arg) / 100
        
        for v in kwargs.values():
            if isinstance(v, (list, tuple)):
                complexity += len(v)
            elif isinstance(v, np.ndarray):
                complexity += v.size
            elif isinstance(v, (int, float)):
                complexity += abs(v) / 100
        
        return complexity
    
    @staticmethod
    def get_adaptive_ttl(complexity: float) -> int:
        """æ ¹æ®å¤æ‚åº¦è¿”å›TTL"""
        if complexity < 100:
            return 300      # 5åˆ†é’Ÿ
        elif complexity < 1000:
            return 1800     # 30åˆ†é’Ÿ
        elif complexity < 10000:
            return 3600     # 1å°æ—¶
        else:
            return 7200     # 2å°æ—¶
    
    def __call__(self, func: Callable) -> Callable:
        """è£…é¥°å™¨"""
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # è®¡ç®—å¤æ‚åº¦
            complexity = self.calculate_complexity(args, kwargs)
            ttl = self.get_adaptive_ttl(complexity)
            
            # åˆ›å»ºåŠ¨æ€ç¼“å­˜
            @st.cache_data(ttl=ttl)
            def cached_func(*args, **kwargs):
                return func(*args, **kwargs)
            
            return cached_func(*args, **kwargs)
        
        return wrapper


# ä¾¿æ·çš„é¢„å®šä¹‰è£…é¥°å™¨
cache_fast = lambda func: st.cache_data(ttl=CacheConfig.TTL_CONFIGS['fast'])(func)
cache_medium = lambda func: st.cache_data(ttl=CacheConfig.TTL_CONFIGS['medium'])(func)
cache_heavy = lambda func: st.cache_data(ttl=CacheConfig.TTL_CONFIGS['heavy'])(func)
cache_static = lambda func: st.cache_data(ttl=None)(func)


class CacheMonitor:
    """ç¼“å­˜ç›‘æ§å™¨ - æ˜¾ç¤ºç¼“å­˜æ€§èƒ½ç»Ÿè®¡"""
    
    @staticmethod
    def show_cache_stats():
        """æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        if st.session_state.get('show_cache_stats', False):
            with st.expander("ğŸ“Š ç¼“å­˜ç»Ÿè®¡", expanded=False):
                # è·å–ç¼“å­˜ç»Ÿè®¡
                cache_stats = st.cache_data.cache_stats()
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ç¼“å­˜å‘½ä¸­", cache_stats.get('hits', 0))
                with col2:
                    st.metric("ç¼“å­˜æœªå‘½ä¸­", cache_stats.get('misses', 0))
                with col3:
                    hit_rate = cache_stats.get('hits', 0) / max(1, cache_stats.get('hits', 0) + cache_stats.get('misses', 0))
                    st.metric("å‘½ä¸­ç‡", f"{hit_rate*100:.1f}%")
                
                if st.button("ğŸ—‘ï¸ æ¸…é™¤ç¼“å­˜"):
                    st.cache_data.clear()
                    st.success("ç¼“å­˜å·²æ¸…é™¤")
                    st.rerun()


# ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µ
USAGE_EXAMPLES = """
# ============================================================================
# æ™ºèƒ½ç¼“å­˜ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

# 1. ç®€å•ä½¿ç”¨ - å¿«é€Ÿè®¡ç®—
@cache_fast
def simple_calculation(x, y):
    return x + y

# 2. ä¸­ç­‰è®¡ç®— - é»˜è®¤æ¨è
@cache_medium
def moderate_calculation(n):
    return np.random.randn(n, n).sum()

# 3. é‡å‹è®¡ç®— - é•¿æ—¶é—´ç¼“å­˜
@cache_heavy
def heavy_calculation(size):
    matrix = np.random.randn(size, size)
    return np.linalg.svd(matrix)

# 4. NumPyä¸“ç”¨ç¼“å­˜
@cache_numpy_computation(ttl=3600)
def matrix_operation(A, B):
    return A @ B + np.linalg.inv(A)

# 5. è‡ªé€‚åº”ç¼“å­˜ - è‡ªåŠ¨é€‰æ‹©TTL
@AdaptiveCache()
def adaptive_func(data):
    # æ•°æ®é‡å¤§æ—¶è‡ªåŠ¨å»¶é•¿ç¼“å­˜æ—¶é—´
    return expensive_operation(data)

# 6. æ¸è¿›å¼ç¼“å­˜ - åˆ†é˜¶æ®µç¼“å­˜
progressive = ProgressiveCache(['load', 'process', 'analyze'])

@progressive.cache_stage('load')
def load_data(path):
    return load_large_file(path)

@progressive.cache_stage('process')
def process_data(data):
    return heavy_processing(data)

@progressive.cache_stage('analyze')
def analyze_data(processed):
    return complex_analysis(processed)

# 7. æ™ºèƒ½ç¼“å­˜ - å¸¦ç»Ÿè®¡
@SmartCache(cache_type='auto', show_stats=True)
def smart_computation(params):
    return do_computation(params)

# ============================================================================
# æœ€ä½³å®è·µ
# ============================================================================

# âœ… å¥½çš„åšæ³•ï¼š
# 1. ä¸ºçº¯å‡½æ•°ä½¿ç”¨ç¼“å­˜ï¼ˆè¾“å…¥ç›¸åŒï¼Œè¾“å‡ºç›¸åŒï¼‰
# 2. ç¼“å­˜è€—æ—¶ > 0.1ç§’çš„è®¡ç®—
# 3. æ ¹æ®æ•°æ®æ›´æ–°é¢‘ç‡é€‰æ‹©TTL
# 4. ä½¿ç”¨é€‚å½“çš„ç¼“å­˜ç±»å‹

# âŒ é¿å…ï¼š
# 1. ç¼“å­˜æœ‰å‰¯ä½œç”¨çš„å‡½æ•°
# 2. ç¼“å­˜è¿”å›éšæœºç»“æœçš„å‡½æ•°
# 3. ç¼“å­˜è¶…å¤§å¯¹è±¡ï¼ˆ> 100MBï¼‰
# 4. è¿‡åº¦ç¼“å­˜ï¼ˆå†…å­˜æº¢å‡ºï¼‰
"""
