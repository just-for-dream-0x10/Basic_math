"""
äº¤äº’å¼ç¥ç»è¿›åŒ–ä¸è¿›åŒ–ç­–ç•¥å¯è§†åŒ–
ä¸¥æ ¼æŒ‰ç…§ 14.Neuroevolution.md ä¸­çš„å…¬å¼å®ç°
"""

import streamlit as st
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pandas as pd
from scipy.stats import multivariate_normal
import warnings
import sys
import os

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥commonæ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from common.error_handler import safe_render
from common.quiz_system import QuizSystem, QuizTemplates
from common.smart_cache import cache_medium, cache_heavy, cache_numpy_computation

warnings.filterwarnings('ignore')


class InteractiveNeuroevolution:
    """äº¤äº’å¼ç¥ç»è¿›åŒ–ä¸è¿›åŒ–ç­–ç•¥å¯è§†åŒ–"""
    
    @staticmethod
    @safe_render

    def render():
        st.subheader("ğŸ§¬ ç¥ç»è¿›åŒ–ä¸è¿›åŒ–ç­–ç•¥ï¼šé›¶é˜¶ä¼˜åŒ–è¶…è¶Šæ¢¯åº¦")
        st.markdown("""
        **æ ¸å¿ƒæ€æƒ³**: è¿›åŒ–ç­–ç•¥é€šè¿‡ç¾¤ä½“æœç´¢å’Œéšæœºé‡‡æ ·ï¼Œåœ¨ä¸å¯å¾®ã€éå‡¸ã€ç¨€ç–å¥–åŠ±çš„åœºæ™¯ä¸­è¶…è¶Šæ¢¯åº¦ä¸‹é™
        
        å…³é”®æ¦‚å¿µï¼š
        - **é›¶é˜¶ä¼˜åŒ–**: $\\nabla_\\theta J(\\theta) \\approx \\frac{1}{\\sigma N} \\sum_{i=1}^N F(\\theta + \\epsilon_i) \\cdot \\epsilon_i$
        - **é«˜æ–¯å¹³æ»‘**: $J(\\theta) = \\mathbb{E}_{\\epsilon \\sim \\mathcal{N}(\\theta, \\sigma^2 I)} [F(\\theta + \\epsilon)]$
        - **é•œåƒé‡‡æ ·**: $R_i^+ = F(\\theta_t + \\epsilon_i \\sigma)$ å’Œ $R_i^- = F(\\theta_t - \\epsilon_i \\sigma)$
        - **åæ–¹å·®é€‚åº”**: CMA-ES å­¦ä¹ å‚æ•°ç›¸å…³æ€§ï¼Œæ¤­çƒæ¢ç´¢
        """)
        
        with st.sidebar:
            st.markdown("### ğŸ“Š å¯è§†åŒ–é€‰æ‹©")
            viz_type = st.selectbox("é€‰æ‹©å¯è§†åŒ–ç±»å‹", 
                ["ES vs æ¢¯åº¦ä¸‹é™", "OpenAI ESç®—æ³•", "PBTç§ç¾¤è®­ç»ƒ", "CMA-ESåæ–¹å·®é€‚åº”"])
            
            st.markdown("### ğŸ›ï¸ å‚æ•°è°ƒæ•´")
        
        if viz_type == "ES vs æ¢¯åº¦ä¸‹é™":
            InteractiveNeuroevolution._render_es_vs_gd()
        elif viz_type == "OpenAI ESç®—æ³•":
            InteractiveNeuroevolution._render_openai_es()
        elif viz_type == "PBTç§ç¾¤è®­ç»ƒ":
            InteractiveNeuroevolution._render_pbt()
        elif viz_type == "CMA-ESåæ–¹å·®é€‚åº”":
            InteractiveNeuroevolution._render_cma_es()
    

        # æ·»åŠ äº¤äº’å¼æµ‹éªŒ
        quiz_system = QuizSystem("neuroevolution")
        quizzes = QuizTemplates.get_neuroevolution_quizzes()
        quiz_system.render_quiz(quizzes)
    @staticmethod
    def _render_es_vs_gd():
        """ES vs æ¢¯åº¦ä¸‹é™å¯¹æ¯”æ¼”ç¤º"""
        st.markdown("### ğŸ¥¾ ç™»å±±è€… vs ç©ºé™å…µï¼šES vs æ¢¯åº¦ä¸‹é™")
        
        with st.sidebar:
            test_function = st.selectbox("æµ‹è¯•å‡½æ•°", 
                ["Rastrigin (å¤šå³°)", "Rosenbrock (å³¡è°·)", "Ackley (å¹³å°)", "Sphere (ç®€å•)"])
            num_iterations = st.slider("è¿­ä»£æ¬¡æ•°", 50, 200, 100, 10)
            population_size = st.slider("ç§ç¾¤å¤§å°", 10, 100, 50, 10)
            learning_rate = st.slider("å­¦ä¹ ç‡", 0.001, 0.1, 0.01, 0.001)
            noise_std = st.slider("å™ªå£°æ ‡å‡†å·®", 0.01, 0.5, 0.1, 0.01)
        
        # å®šä¹‰æµ‹è¯•å‡½æ•°
        def rastrigin(x):
            A = 10
            return A * len(x) + sum([(xi**2 - A * np.cos(2 * np.pi * xi)) for xi in x])
        
        def rosenbrock(x):
            return sum([100 * (x[i+1] - x[i]**2)**2 + (1 - x[i])**2 for i in range(len(x)-1)])
        
        def ackley(x):
            a, b, c = 20, 0.2, 2 * np.pi
            sum1 = sum([xi**2 for xi in x])
            sum2 = sum([np.cos(c * xi) for xi in x])
            return -a * np.exp(-b * np.sqrt(sum1 / len(x))) - np.exp(sum2 / len(x)) + a + np.e
        
        def sphere(x):
            return sum([xi**2 for xi in x])
        
        # é€‰æ‹©æµ‹è¯•å‡½æ•°
        if test_function == "Rastrigin (å¤šå³°)":
            func = rastrigin
            bounds = (-5.12, 5.12)
        elif test_function == "Rosenbrock (å³¡è°·)":
            func = rosenbrock
            bounds = (-2, 2)
        elif test_function == "Ackley (å¹³å°)":
            func = ackley
            bounds = (-5, 5)
        else:  # Sphere
            func = sphere
            bounds = (-2, 2)
        
        # æ¢¯åº¦ä¸‹é™ (éœ€è¦æ•°å€¼æ¢¯åº¦)
        def numerical_gradient(f, x, eps=1e-6):
            grad = np.zeros_like(x)
            for i in range(len(x)):
                x_plus = x.copy()
                x_minus = x.copy()
                x_plus[i] += eps
                x_minus[i] -= eps
                grad[i] = (f(x_plus) - f(x_minus)) / (2 * eps)
            return grad
        
        # è¿›åŒ–ç­–ç•¥
        def evolution_strategy(f, x0, num_iter, pop_size, sigma, lr):
            x = x0.copy()
            history = [x.copy()]
            fitness_history = [f(x)]
            
            for t in range(num_iter):
                # ç”Ÿæˆå™ªå£°æ ·æœ¬
                epsilon = np.random.randn(pop_size, len(x))
                fitness = np.array([f(x + sigma * e) for e in epsilon])
                
                # æ ‡å‡†åŒ–é€‚åº”åº¦
                fitness = (fitness - np.mean(fitness)) / (np.std(fitness) + 1e-8)
                
                # ESæ›´æ–°
                gradient_estimate = np.dot(epsilon.T, fitness) / (pop_size * sigma)
                x = x + lr * gradient_estimate
                
                history.append(x.copy())
                fitness_history.append(f(x))
            
            return np.array(history), np.array(fitness_history)
        
        # æ¢¯åº¦ä¸‹é™
        def gradient_descent(f, x0, num_iter, lr):
            x = x0.copy()
            history = [x.copy()]
            fitness_history = [f(x)]
            
            for t in range(num_iter):
                grad = numerical_gradient(f, x)
                x = x - lr * grad
                
                history.append(x.copy())
                fitness_history.append(f(x))
            
            return np.array(history), np.array(fitness_history)
        
        # åˆå§‹åŒ–
        np.random.seed(42)
        dim = 2
        x0 = np.random.uniform(bounds[0], bounds[1], dim)
        
        # è¿è¡Œç®—æ³•
        es_history, es_fitness = evolution_strategy(func, x0, num_iterations, population_size, noise_std, learning_rate)
        gd_history, gd_fitness = gradient_descent(func, x0, num_iterations, learning_rate)
        
        # å¯è§†åŒ–ä¼˜åŒ–è½¨è¿¹
        fig = make_subplots(
            rows=1, cols=2,
            subplot_titles=["ä¼˜åŒ–è½¨è¿¹ (2DæŠ•å½±)", "æ”¶æ•›æ›²çº¿"],
            specs=[[{"type": "scatter"}, {"type": "scatter"}]]
        )
        
        # è½¨è¿¹å›¾
        fig.add_trace(
            go.Scatter(
                x=es_history[:, 0], y=es_history[:, 1],
                mode='lines+markers',
                name='ESç­–ç•¥',
                line=dict(color='red', width=2),
                marker=dict(size=4)
            ),
            row=1, col=1
        )
        
        fig.add_trace(
            go.Scatter(
                x=gd_history[:, 0], y=gd_history[:, 1],
                mode='lines+markers',
                name='æ¢¯åº¦ä¸‹é™',
                line=dict(color='blue', width=2),
                marker=dict(size=4)
            ),
            row=1, col=1
        )
        
        # æ”¶æ•›æ›²çº¿
        fig.add_trace(
            go.Scatter(
                x=np.arange(len(es_fitness)), y=es_fitness,
                mode='lines',
                name='ESé€‚åº”åº¦',
                line=dict(color='red', width=2)
            ),
            row=1, col=2
        )
        
        fig.add_trace(
            go.Scatter(
                x=np.arange(len(gd_fitness)), y=gd_fitness,
                mode='lines',
                name='GDæŸå¤±',
                line=dict(color='blue', width=2)
            ),
            row=1, col=2
        )
        
        fig.update_layout(
            title=f"ES vs æ¢¯åº¦ä¸‹é™ - {test_function}",
            height=500,
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # æ€§èƒ½æŒ‡æ ‡
        st.markdown("### ğŸ“Š æ€§èƒ½å¯¹æ¯”")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ESæœ€ç»ˆå€¼", f"{es_fitness[-1]:.4f}")
        with col2:
            st.metric("GDæœ€ç»ˆå€¼", f"{gd_fitness[-1]:.4f}")
        with col3:
            improvement = (gd_fitness[-1] - es_fitness[-1]) / abs(gd_fitness[-1]) * 100
            st.metric("ESæ”¹è¿›", f"{improvement:.1f}%", delta=f"{improvement:.1f}%")
        
        # ç®—æ³•ç‰¹æ€§å¯¹æ¯”
        st.markdown("### ğŸ”„ ç®—æ³•ç‰¹æ€§å¯¹æ¯”")
        
        comparison_data = {
            "ç‰¹æ€§": ["å¯¼æ•°éœ€æ±‚", "å¹¶è¡Œæ€§", "å±€éƒ¨æœ€ä¼˜é€ƒé¿", "æ ·æœ¬æ•ˆç‡", "é«˜ç»´é€‚åº”"],
            "ESç­–ç•¥": ["ä¸éœ€è¦", "é«˜", "å¼º", "ä½", "å·®"],
            "æ¢¯åº¦ä¸‹é™": ["å¿…éœ€", "ä½", "å¼±", "é«˜", "å¥½"]
        }
        
        df_comparison = pd.DataFrame(comparison_data)
        st.dataframe(df_comparison, use_container_width=True)
        
        st.info("""
        **å…³é”®æ´å¯Ÿ**ï¼š
        - ESåœ¨å¤šå³°å‡½æ•°ä¸Šè¡¨ç°æ›´å¥½ï¼Œå› ä¸ºç¾¤ä½“æœç´¢èƒ½è·³å‡ºå±€éƒ¨æœ€ä¼˜
        - æ¢¯åº¦ä¸‹é™åœ¨å…‰æ»‘å‡½æ•°ä¸Šæ›´é«˜æ•ˆï¼Œä½†å®¹æ˜“é™·å…¥å³¡è°·æˆ–å¹³å°
        - ESçš„å¹¶è¡Œæ€§ä½¿å…¶åœ¨å¤§è§„æ¨¡è®¡ç®—ä¸­å…·æœ‰ä¼˜åŠ¿
        - æ ·æœ¬æ•ˆç‡æ˜¯ESçš„ä¸»è¦ç“¶é¢ˆï¼Œç‰¹åˆ«åœ¨æ•°æ®è·å–æ˜‚è´µçš„åœºæ™¯
        """)
    
    @staticmethod
    def _render_openai_es():
        """OpenAI ESç®—æ³•æ¼”ç¤º"""
        st.markdown("### ğŸš€ OpenAI ESï¼šé•œåƒé‡‡æ ·ä¸æ–¹å·®ä¼˜åŒ–")
        
        st.latex(r"""
        \theta_{t+1} = \theta_t + \alpha \cdot \frac{1}{n\sigma} \sum_{i=1}^n (R_i^+ - R_i^-) \epsilon_i
        """)
        
        with st.sidebar:
            population_size = st.slider("ç§ç¾¤å¤§å°", 10, 100, 32, 2)
            sigma = st.slider("å™ªå£°å¼ºåº¦", 0.01, 0.5, 0.1, 0.01)
            learning_rate = st.slider("å­¦ä¹ ç‡", 0.001, 0.1, 0.02, 0.001)
            use_mirror_sampling = st.checkbox("ä½¿ç”¨é•œåƒé‡‡æ ·", value=True)
            num_iterations = st.slider("è¿­ä»£æ¬¡æ•°", 50, 200, 100, 10)
        
        # ç›®æ ‡å‡½æ•° (ç®€å•çš„äºŒæ¬¡å‡½æ•°)
        def target_function(theta):
            """ç®€å•çš„äºŒæ¬¡ç›®æ ‡å‡½æ•°ï¼Œæœ€å°åŒ– ||theta - target||^2"""
            target = np.array([1.0, 2.0])
            return -np.sum((theta - target)**2)  # è´Ÿå·å› ä¸ºæˆ‘ä»¬è¦æœ€å¤§åŒ–
        
        # OpenAI ESå®ç°
        def openai_es(f, theta0, num_iter, pop_size, sigma, lr, mirror=True):
            theta = theta0.copy()
            history = [theta.copy()]
            fitness_history = [f(theta)]
            
            for t in range(num_iter):
                if mirror:
                    # é•œåƒé‡‡æ ·
                    epsilon = np.random.randn(pop_size // 2, len(theta))
                    epsilon_full = np.concatenate([epsilon, -epsilon])
                    
                    # è¯„ä¼°æ­£è´Ÿæ‰°åŠ¨
                    rewards_plus = np.array([f(theta + sigma * e) for e in epsilon])
                    rewards_minus = np.array([f(theta - sigma * e) for e in epsilon])
                    
                    # ç»„åˆå¥–åŠ±
                    rewards_diff = rewards_plus - rewards_minus
                    rewards_diff = np.concatenate([rewards_diff, -rewards_diff])
                else:
                    # æ ‡å‡†é‡‡æ ·
                    epsilon_full = np.random.randn(pop_size, len(theta))
                    rewards = np.array([f(theta + sigma * e) for e in epsilon_full])
                    rewards_diff = rewards
                
                # æ ‡å‡†åŒ–å¥–åŠ±
                rewards_diff = (rewards_diff - np.mean(rewards_diff)) / (np.std(rewards_diff) + 1e-8)
                
                # æ›´æ–°å‚æ•°
                gradient_estimate = np.dot(epsilon_full.T, rewards_diff) / (pop_size * sigma)
                theta = theta + lr * gradient_estimate
                
                history.append(theta.copy())
                fitness_history.append(f(theta))
            
            return np.array(history), np.array(fitness_history)
        
        # è¿è¡Œç®—æ³•
        np.random.seed(42)
        theta0 = np.array([0.0, 0.0])
        
        # å¯¹æ¯”é•œåƒé‡‡æ · vs æ ‡å‡†é‡‡æ ·
        history_mirror, fitness_mirror = openai_es(
            target_function, theta0, num_iterations, population_size, sigma, learning_rate, mirror=True
        )
        history_standard, fitness_standard = openai_es(
            target_function, theta0, num_iterations, population_size, sigma, learning_rate, mirror=False
        )
        
        # å¯è§†åŒ–ç»“æœ
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=[
                "å‚æ•°è½¨è¿¹ (é•œåƒé‡‡æ ·)", "å‚æ•°è½¨è¿¹ (æ ‡å‡†é‡‡æ ·)",
                "é€‚åº”åº¦æ›²çº¿å¯¹æ¯”", "æ–¹å·®åˆ†æ"
            ]
        )
        
        # é•œåƒé‡‡æ ·è½¨è¿¹
        fig.add_trace(
            go.Scatter(
                x=history_mirror[:, 0], y=history_mirror[:, 1],
                mode='lines+markers',
                name='é•œåƒé‡‡æ ·',
                line=dict(color='blue', width=2)
            ),
            row=1, col=1
        )
        
        # æ ‡å‡†é‡‡æ ·è½¨è¿¹
        fig.add_trace(
            go.Scatter(
                x=history_standard[:, 0], y=history_standard[:, 1],
                mode='lines+markers',
                name='æ ‡å‡†é‡‡æ ·',
                line=dict(color='red', width=2)
            ),
            row=1, col=2
        )
        
        # é€‚åº”åº¦å¯¹æ¯”
        fig.add_trace(
            go.Scatter(
                x=np.arange(len(fitness_mirror)), y=fitness_mirror,
                mode='lines',
                name='é•œåƒé‡‡æ ·',
                line=dict(color='blue', width=2)
            ),
            row=2, col=1
        )
        
        fig.add_trace(
            go.Scatter(
                x=np.arange(len(fitness_standard)), y=fitness_standard,
                mode='lines',
                name='æ ‡å‡†é‡‡æ ·',
                line=dict(color='red', width=2)
            ),
            row=2, col=1
        )
        
        # æ–¹å·®åˆ†æ
        mirror_var = np.var(fitness_mirror[-20:])  # æœ€å20æ­¥çš„æ–¹å·®
        standard_var = np.var(fitness_standard[-20:])
        
        fig.add_trace(
            go.Bar(
                x=['é•œåƒé‡‡æ ·', 'æ ‡å‡†é‡‡æ ·'],
                y=[mirror_var, standard_var],
                marker_color=['lightblue', 'lightcoral']
            ),
            row=2, col=2
        )
        
        fig.update_layout(
            title="OpenAI ES ç®—æ³•åˆ†æ",
            height=600,
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # æ€§èƒ½æŒ‡æ ‡
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("é•œåƒæœ€ç»ˆå€¼", f"{fitness_mirror[-1]:.4f}")
        with col2:
            st.metric("æ ‡å‡†æœ€ç»ˆå€¼", f"{fitness_standard[-1]:.4f}")
        with col3:
            st.metric("é•œåƒæ–¹å·®", f"{mirror_var:.6f}")
        with col4:
            st.metric("æ ‡å‡†æ–¹å·®", f"{standard_var:.6f}")
        
        # ç®—æ³•æ­¥éª¤å¯è§†åŒ–
        st.markdown("### ğŸ”„ å•æ­¥ç®—æ³•æ¼”ç¤º")
        
        # å±•ç¤ºå•æ­¥çš„é‡‡æ ·å’Œè¯„ä¼°è¿‡ç¨‹
        step_demo = st.slider("é€‰æ‹©æ¼”ç¤ºæ­¥éª¤", 0, min(num_iterations-1, 10), 0)
        
        if step_demo > 0:
            theta_current = history_mirror[step_demo]
            
            # ç”Ÿæˆé‡‡æ ·ç‚¹
            epsilon_demo = np.random.randn(population_size // 2, len(theta_current))
            epsilon_full_demo = np.concatenate([epsilon_demo, -epsilon_demo])
            
            # è®¡ç®—å¥–åŠ±
            rewards_plus_demo = np.array([target_function(theta_current + sigma * e) for e in epsilon_demo])
            rewards_minus_demo = np.array([target_function(theta_current - sigma * e) for e in epsilon_demo])
            
            # å¯è§†åŒ–é‡‡æ ·åˆ†å¸ƒ
            fig_demo = go.Figure()
            
            # æ­£æ‰°åŠ¨ç‚¹
            pos_points = theta_current + sigma * epsilon_demo
            fig_demo.add_trace(go.Scatter(
                x=pos_points[:, 0], y=pos_points[:, 1],
                mode='markers',
                name='æ­£æ‰°åŠ¨',
                marker=dict(color='green', size=8, opacity=0.7),
                text=[f"R+: {r:.3f}" for r in rewards_plus_demo]
            ))
            
            # è´Ÿæ‰°åŠ¨ç‚¹
            neg_points = theta_current - sigma * epsilon_demo
            fig_demo.add_trace(go.Scatter(
                x=neg_points[:, 0], y=neg_points[:, 1],
                mode='markers',
                name='è´Ÿæ‰°åŠ¨',
                marker=dict(color='red', size=8, opacity=0.7),
                text=[f"R-: {r:.3f}" for r in rewards_minus_demo]
            ))
            
            # å½“å‰å‚æ•°ç‚¹
            fig_demo.add_trace(go.Scatter(
                x=[theta_current[0]], y=[theta_current[1]],
                mode='markers',
                name='å½“å‰å‚æ•°',
                marker=dict(color='blue', size=15, symbol='star')
            ))
            
            # ç›®æ ‡ç‚¹
            target_point = np.array([1.0, 2.0])
            fig_demo.add_trace(go.Scatter(
                x=[target_point[0]], y=[target_point[1]],
                mode='markers',
                name='ç›®æ ‡',
                marker=dict(color='gold', size=15, symbol='diamond')
            ))
            
            fig_demo.update_layout(
                title=f"æ­¥éª¤ {step_demo} é‡‡æ ·åˆ†å¸ƒ",
                xaxis_title="å‚æ•° 1",
                yaxis_title="å‚æ•° 2",
                height=500
            )
            
            st.plotly_chart(fig_demo, use_container_width=True)
        
        st.success("""
        **OpenAI ES çš„ä¼˜åŠ¿**ï¼š
        - é•œåƒé‡‡æ ·æ˜¾è‘—é™ä½æ–¹å·®ï¼Œæé«˜æ”¶æ•›ç¨³å®šæ€§
        - æ— éœ€åå‘ä¼ æ’­ï¼Œè®¡ç®—å›¾ç®€å•
        - å¤©ç„¶é€‚åˆåˆ†å¸ƒå¼è®­ç»ƒ
        - å¯¹æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸ä¸æ•æ„Ÿ
        """)
    
    @staticmethod
    def _render_pbt():
        """PBTç§ç¾¤è®­ç»ƒæ¼”ç¤º"""
        st.markdown("### ğŸ§¬ PBTï¼šåŸºäºç§ç¾¤çš„è®­ç»ƒ")
        
        st.markdown("""
        **æ ¸å¿ƒæ€æƒ³**ï¼š
        - **Exploit (åˆ©ç”¨)**ï¼šè¡¨ç°å·®çš„æ¨¡å‹å¤åˆ¶è¡¨ç°å¥½çš„æ¨¡å‹å‚æ•°
        - **Explore (æ¢ç´¢)**ï¼šå¯¹ç»§æ‰¿çš„è¶…å‚æ•°è¿›è¡Œéšæœºæ‰°åŠ¨
        - **åŒå±‚ä¼˜åŒ–**ï¼šå†…å±‚SGDä¼˜åŒ–æƒé‡ï¼Œå¤–å±‚è¿›åŒ–ä¼˜åŒ–è¶…å‚æ•°
        """)
        
        with st.sidebar:
            population_size = st.slider("ç§ç¾¤å¤§å°", 4, 16, 8, 2)
            num_generations = st.slider("ä»£æ•°", 10, 50, 20, 5)
            exploit_interval = st.slider("åˆ©ç”¨é—´éš”", 2, 10, 5, 1)
            mutation_strength = st.slider("å˜å¼‚å¼ºåº¦", 0.1, 0.5, 0.2, 0.05)
            initial_lr_range = st.slider("åˆå§‹å­¦ä¹ ç‡èŒƒå›´", 0.001, 0.1, (0.01, 0.05))
        
        # PBTç®—æ³•å®ç°
        class PBTAgent:
            def __init__(self, agent_id, lr, momentum):
                self.id = agent_id
                self.lr = lr
                self.momentum = momentum
                self.weights = np.random.randn(2) * 0.1
                self.fitness_history = []
                self.age = 0
            
            def train_step(self, target_function, steps=5):
                """æ¨¡æ‹Ÿå‡ æ­¥è®­ç»ƒ"""
                for _ in range(steps):
                    # ç®€å•çš„æ¢¯åº¦ä¸‹é™æ­¥éª¤
                    grad = self._compute_gradient(target_function)
                    self.weights = self.weights - self.lr * grad
                self.age += 1
            
            def _compute_gradient(self, target_function, eps=1e-6):
                """æ•°å€¼æ¢¯åº¦"""
                grad = np.zeros_like(self.weights)
                for i in range(len(self.weights)):
                    w_plus = self.weights.copy()
                    w_minus = self.weights.copy()
                    w_plus[i] += eps
                    w_minus[i] -= eps
                    grad[i] = (target_function(w_plus) - target_function(w_minus)) / (2 * eps)
                return grad
            
            def evaluate(self, target_function):
                """è¯„ä¼°å½“å‰æ€§èƒ½"""
                fitness = target_function(self.weights)
                self.fitness_history.append(fitness)
                return fitness
            
            def copy_from(self, other):
                """å¤åˆ¶å¦ä¸€ä¸ªæ™ºèƒ½ä½“çš„å‚æ•°"""
                self.weights = other.weights.copy()
                self.fitness_history = other.fitness_history.copy()
            
            def mutate_hyperparams(self):
                """å˜å¼‚è¶…å‚æ•°"""
                self.lr *= np.random.uniform(1 - mutation_strength, 1 + mutation_strength)
                self.lr = np.clip(self.lr, 0.001, 0.1)
                self.momentum *= np.random.uniform(1 - mutation_strength, 1 + mutation_strength)
                self.momentum = np.clip(self.momentum, 0.0, 0.99)
        
        # ç›®æ ‡å‡½æ•°
        def target_function(weights):
            target = np.array([1.0, 2.0])
            return -np.sum((weights - target)**2)
        
        # åˆå§‹åŒ–ç§ç¾¤
        np.random.seed(42)
        population = []
        for i in range(population_size):
            lr = np.random.uniform(initial_lr_range[0], initial_lr_range[1])
            momentum = np.random.uniform(0.5, 0.95)
            population.append(PBTAgent(i, lr, momentum))
        
        # PBTè®­ç»ƒå¾ªç¯
        history = {
            'weights': [],
            'lr': [],
            'fitness': [],
            'exploit_events': []
        }
        
        for generation in range(num_generations):
            # è®­ç»ƒæ¯ä¸ªæ™ºèƒ½ä½“
            for agent in population:
                agent.train_step(target_function)
            
            # è¯„ä¼°ç§ç¾¤
            fitnesses = [agent.evaluate(target_function) for agent in population]
            
            # è®°å½•å†å²
            history['weights'].append([agent.weights.copy() for agent in population])
            history['lr'].append([agent.lr for agent in population])
            history['fitness'].append(fitnesses)
            
            # PBTåˆ©ç”¨å’Œæ¢ç´¢
            if generation % exploit_interval == 0 and generation > 0:
                # æ‰¾åˆ°è¡¨ç°æœ€å¥½å’Œæœ€å·®çš„æ™ºèƒ½ä½“
                best_idx = np.argmax(fitnesses)
                worst_idx = np.argmin(fitnesses)
                
                # åˆ©ç”¨ï¼šæœ€å·®çš„å¤åˆ¶æœ€å¥½çš„
                population[worst_idx].copy_from(population[best_idx])
                
                # æ¢ç´¢ï¼šå˜å¼‚è¶…å‚æ•°
                population[worst_idx].mutate_hyperparams()
                
                history['exploit_events'].append({
                    'generation': generation,
                    'best': best_idx,
                    'worst': worst_idx
                })
        
        # å¯è§†åŒ–PBTè¿‡ç¨‹
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=[
                "ç§ç¾¤é€‚åº”åº¦æ¼”åŒ–", "å­¦ä¹ ç‡æ¼”åŒ–",
                "å‚æ•°ç©ºé—´è½¨è¿¹", "åˆ©ç”¨/æ¢ç´¢äº‹ä»¶"
            ]
        )
        
        # é€‚åº”åº¦æ¼”åŒ–
        for i in range(population_size):
            fitness_traj = [gen[i] for gen in history['fitness']]
            fig.add_trace(
                go.Scatter(
                    x=np.arange(len(fitness_traj)),
                    y=fitness_traj,
                    mode='lines',
                    name=f'æ™ºèƒ½ä½“ {i}',
                    line=dict(width=2)
                ),
                row=1, col=1
            )
        
        # å­¦ä¹ ç‡æ¼”åŒ–
        for i in range(population_size):
            lr_traj = [gen[i] for gen in history['lr']]
            fig.add_trace(
                go.Scatter(
                    x=np.arange(len(lr_traj)),
                    y=lr_traj,
                    mode='lines',
                    name=f'æ™ºèƒ½ä½“ {i} LR',
                    line=dict(width=2, dash='dash'),
                    showlegend=False
                ),
                row=1, col=2
            )
        
        # å‚æ•°ç©ºé—´è½¨è¿¹ (åªæ˜¾ç¤ºå‰3ä¸ªæ™ºèƒ½ä½“é¿å…æ··ä¹±)
        colors = ['blue', 'red', 'green']
        for i in range(min(3, population_size)):
            weights_traj = np.array([gen[i] for gen in history['weights']])
            fig.add_trace(
                go.Scatter(
                    x=weights_traj[:, 0],
                    y=weights_traj[:, 1],
                    mode='lines+markers',
                    name=f'æ™ºèƒ½ä½“ {i} è½¨è¿¹',
                    line=dict(color=colors[i], width=2),
                    marker=dict(size=4)
                ),
                row=2, col=1
            )
        
        # åˆ©ç”¨/æ¢ç´¢äº‹ä»¶
        if history['exploit_events']:
            event_gens = [event['generation'] for event in history['exploit_events']]
            event_fitness = [max(history['fitness'][gen]) for gen in event_gens]
            
            fig.add_trace(
                go.Scatter(
                    x=event_gens,
                    y=event_fitness,
                    mode='markers',
                    name='åˆ©ç”¨/æ¢ç´¢äº‹ä»¶',
                    marker=dict(color='gold', size=10, symbol='star')
                ),
                row=2, col=2
            )
        
        fig.update_layout(
            title="PBT ç§ç¾¤è®­ç»ƒè¿‡ç¨‹",
            height=600,
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # æœ€ç»ˆç§ç¾¤çŠ¶æ€
        st.markdown("### ğŸ† æœ€ç»ˆç§ç¾¤çŠ¶æ€")
        
        final_fitnesses = history['fitness'][-1]
        final_lrs = history['lr'][-1]
        
        results_df = pd.DataFrame({
            'æ™ºèƒ½ä½“': [f'Agent {i}' for i in range(population_size)],
            'æœ€ç»ˆé€‚åº”åº¦': final_fitnesses,
            'æœ€ç»ˆå­¦ä¹ ç‡': final_lrs,
            'å¹´é¾„': [agent.age for agent in population]
        })
        
        st.dataframe(results_df, use_container_width=True)
        
        # PBTä¼˜åŠ¿åˆ†æ
        st.markdown("### ğŸ“ˆ PBT ä¼˜åŠ¿åˆ†æ")
        
        # è®¡ç®—æœ€ä½³æ™ºèƒ½ä½“çš„æ€§èƒ½æå‡
        best_fitness_per_gen = [max(gen) for gen in history['fitness']]
        improvement = (best_fitness_per_gen[-1] - best_fitness_per_gen[0]) / abs(best_fitness_per_gen[0]) * 100
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ€§èƒ½æå‡", f"{improvement:.1f}%")
        with col2:
            st.metric("åˆ©ç”¨äº‹ä»¶", len(history['exploit_events']))
        with col3:
            avg_lr = np.mean(final_lrs)
            st.metric("å¹³å‡å­¦ä¹ ç‡", f"{avg_lr:.4f}")
        
        st.success("""
        **PBT çš„æ ¸å¿ƒä»·å€¼**ï¼š
        - **è‡ªåŠ¨è°ƒå‚**ï¼šé¿å…äººå·¥æœç´¢è¶…å‚æ•°çš„ç¾éš¾
        - **åŠ¨æ€é€‚åº”**ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­è‡ªåŠ¨è°ƒæ•´è¶…å‚æ•°
        - **åŒå±‚ä¼˜åŒ–**ï¼šåŒæ—¶ä¼˜åŒ–æƒé‡å’Œè¶…å‚æ•°
        - **ç§ç¾¤å¤šæ ·æ€§**ï¼šä¿æŒæ¢ç´¢èƒ½åŠ›ï¼Œé¿å…è¿‡æ—©æ”¶æ•›
        """)
    
    @staticmethod
    def _render_cma_es():
        """CMA-ESåæ–¹å·®é€‚åº”æ¼”ç¤º"""
        st.markdown("### ğŸ¯ CMA-ESï¼šåæ–¹å·®çŸ©é˜µé€‚åº”è¿›åŒ–ç­–ç•¥")
        
        st.markdown("""
        **æ ¸å¿ƒçªç ´**ï¼š
        - **æ¤­çƒæ¢ç´¢**ï¼šå­¦ä¹ åæ–¹å·®çŸ©é˜µï¼Œä»åœ†å½¢æ¢ç´¢å˜ä¸ºæ¤­çƒæ¢ç´¢
        - **å‚æ•°ç›¸å…³æ€§**ï¼šè‡ªåŠ¨å­¦ä¹ å‚æ•°é—´çš„ç›¸å…³æ€§
        - **è‡ªé€‚åº”æ­¥é•¿**ï¼šæ ¹æ®æˆåŠŸæ¦‚ç‡è°ƒæ•´æ¢ç´¢å¼ºåº¦
        """)
        
        with st.sidebar:
            population_size = st.slider("ç§ç¾¤å¤§å°", 10, 100, 30, 5)
            num_iterations = st.slider("è¿­ä»£æ¬¡æ•°", 20, 100, 50, 5)
            initial_sigma = st.slider("åˆå§‹æ­¥é•¿", 0.1, 2.0, 0.5, 0.1)
            target_condition = st.selectbox("ç›®æ ‡å‡½æ•°", 
                ["æ¤­åœ†å±±è°·", "æ—‹è½¬æ¤­åœ†", "å¤šå³°å‡½æ•°"])
        
        # å®šä¹‰æµ‹è¯•å‡½æ•°
        def elliptical_valley(x):
            """æ¤­åœ†å±±è°·å‡½æ•°"""
            return 100 * x[0]**2 + x[1]**2
        
        def rotated_elliptical(x):
            """æ—‹è½¬æ¤­åœ†å‡½æ•°"""
            theta = np.pi / 4  # 45åº¦æ—‹è½¬
            rotation = np.array([[np.cos(theta), -np.sin(theta)],
                               [np.sin(theta), np.cos(theta)]])
            x_rotated = rotation @ x
            return 100 * x_rotated[0]**2 + x_rotated[1]**2
        
        def multimodal_function(x):
            """å¤šå³°å‡½æ•°"""
            return (x[0]**2 + x[1]**2) * np.sin(5 * np.sqrt(x[0]**2 + x[1]**2))
        
        # é€‰æ‹©ç›®æ ‡å‡½æ•°
        if target_condition == "æ¤­åœ†å±±è°·":
            target_func = elliptical_valley
            bounds = (-2, 2)
        elif target_condition == "æ—‹è½¬æ¤­åœ†":
            target_func = rotated_elliptical
            bounds = (-2, 2)
        else:  # å¤šå³°å‡½æ•°
            target_func = multimodal_function
            bounds = (-3, 3)
        
        # ç®€åŒ–çš„CMA-ESå®ç°
        class CMAES:
            def __init__(self, dimension, initial_mean, initial_sigma, population_size):
                self.dimension = dimension
                self.mean = initial_mean.copy()
                self.sigma = initial_sigma
                self.population_size = population_size
                self.covariance = np.eye(dimension)
                self.evolution_path = np.zeros(dimension)
                
                # CMA-ESå‚æ•°
                self.cc = 4 / (dimension + 4)
                self.cs = 2 / (dimension + 2)
                self.c1 = 2 / ((dimension + 1.3)**2 + 2)
                self.cmu = min(1 - self.c1, 2 * (2/17) / (dimension**2 + 2))
                self.damps = 1 + 2 * max(0, np.sqrt((population_size - 1) / (dimension + 1)) - 1) + self.cs
            
            def sample(self):
                """ä»å½“å‰åˆ†å¸ƒé‡‡æ ·"""
                samples = []
                # ç¡®ä¿åæ–¹å·®çŸ©é˜µå¯¹ç§°æ­£å®š
                cov_sym = (self.covariance + self.covariance.T) / 2
                eigenvals, eigenvecs = np.linalg.eigh(cov_sym)
                eigenvals = np.maximum(eigenvals, 1e-8)  # ç¡®ä¿ç‰¹å¾å€¼æ­£
                cov_stable = eigenvecs @ np.diag(eigenvals) @ eigenvecs.T
                
                for _ in range(self.population_size):
                    # ä½¿ç”¨Choleskyåˆ†è§£è¿›è¡Œç¨³å®šé‡‡æ ·
                    try:
                        L = np.linalg.cholesky(cov_stable)
                        z = L @ np.random.randn(self.dimension)
                    except np.linalg.LinAlgError:
                        # å¦‚æœCholeskyå¤±è´¥ï¼Œä½¿ç”¨ç‰¹å¾åˆ†è§£æ–¹æ³•
                        z = eigenvecs @ (np.sqrt(eigenvals) * np.random.randn(self.dimension))
                    
                    x = self.mean + self.sigma * z
                    samples.append(x)
                return np.array(samples)
            
            def update(self, samples, fitness_values):
                """æ›´æ–°åˆ†å¸ƒå‚æ•°"""
                # é€‰æ‹©æœ€å¥½çš„ä¸ªä½“
                selected_indices = np.argsort(fitness_values)[:self.population_size//2]
                selected_samples = samples[selected_indices]
                
                # è®¡ç®—æ–°å‡å€¼
                old_mean = self.mean.copy()
                self.mean = np.mean(selected_samples, axis=0)
                
                # æ›´æ–°è¿›åŒ–è·¯å¾„
                self.evolution_path = (1 - self.cc) * self.evolution_path + \
                                    np.sqrt(self.cc * (2 - self.cc) * self.population_size) * \
                                    (self.mean - old_mean) / self.sigma
                
                # æ›´æ–°åæ–¹å·®çŸ©é˜µ
                y = selected_samples - old_mean
                rank_one_update = np.outer(self.evolution_path, self.evolution_path)
                
                # æ‰‹åŠ¨è®¡ç®—åæ–¹å·®ï¼Œé¿å…np.covçš„æ•°å€¼é—®é¢˜
                if y.shape[0] > 1:
                    rank_mu_update = np.dot(y.T, y) / (y.shape[0] - 1)
                    # æ£€æŸ¥è®¡ç®—ç»“æœ
                    if not np.all(np.isfinite(rank_mu_update)):
                        print("è­¦å‘Šï¼šrank_mu_updateåŒ…å«å¼‚å¸¸å€¼ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                        rank_mu_update = np.eye(self.dimension) * 0.01
                else:
                    rank_mu_update = np.eye(self.dimension) * 0.01
                
                self.covariance = (1 - self.c1 - self.cmu) * self.covariance + \
                                self.c1 * rank_one_update + \
                                self.cmu * rank_mu_update
                
                # å¼ºåˆ¶æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
                if not np.all(np.isfinite(self.covariance)):
                    print("è­¦å‘Šï¼šåæ–¹å·®çŸ©é˜µåŒ…å«æ— ç©·å¤§æˆ–NaNï¼Œé‡ç½®ä¸ºå•ä½çŸ©é˜µ")
                    self.covariance = np.eye(self.dimension)
                
                # ç¡®ä¿åæ–¹å·®çŸ©é˜µå¯¹ç§°æ­£å®š
                self.covariance = (self.covariance + self.covariance.T) / 2
                
                # æ£€æŸ¥ç‰¹å¾å€¼å¹¶ä¿®æ­£
                try:
                    eigenvals = np.linalg.eigvals(self.covariance)
                    if np.min(eigenvals) < 1e-8 or not np.all(np.isfinite(eigenvals)):
                        self.covariance += 1e-6 * np.eye(self.dimension)
                except np.linalg.LinAlgError:
                    print("è­¦å‘Šï¼šç‰¹å¾å€¼åˆ†è§£å¤±è´¥ï¼Œé‡ç½®åæ–¹å·®çŸ©é˜µ")
                    self.covariance = np.eye(self.dimension)
                
                # æ›´æ–°æ­¥é•¿ï¼ˆå¸¦æ•°å€¼æ£€æŸ¥ï¼‰
                path_norm = np.linalg.norm(self.evolution_path)
                if np.isfinite(path_norm) and path_norm > 0:
                    update_factor = self.cs / self.damps * (path_norm / np.sqrt(self.dimension) - 1)
                    if np.isfinite(update_factor):
                        self.sigma *= np.exp(update_factor)
                        # é™åˆ¶æ­¥é•¿èŒƒå›´
                        self.sigma = np.clip(self.sigma, 1e-8, 10.0)
                    else:
                        print("è­¦å‘Šï¼šæ­¥é•¿æ›´æ–°å› å­å¼‚å¸¸ï¼Œè·³è¿‡æ›´æ–°")
                else:
                    print("è­¦å‘Šï¼šè¿›åŒ–è·¯å¾„èŒƒæ•°å¼‚å¸¸ï¼Œè·³è¿‡æ­¥é•¿æ›´æ–°")
        
        # è¿è¡ŒCMA-ES
        np.random.seed(42)
        dimension = 2
        initial_mean = np.array([1.5, 1.5])
        
        cma = CMAES(dimension, initial_mean, initial_sigma, population_size)
        
        history = {
            'mean': [initial_mean.copy()],
            'covariance': [np.eye(dimension)],
            'sigma': [initial_sigma],
            'fitness': [target_func(initial_mean)]
        }
        
        for iteration in range(num_iterations):
            # é‡‡æ ·
            samples = cma.sample()
            
            # è¯„ä¼°
            fitness_values = np.array([target_func(sample) for sample in samples])
            
            # æ›´æ–°
            cma.update(samples, fitness_values)
            
            # è®°å½•å†å²
            history['mean'].append(cma.mean.copy())
            history['covariance'].append(cma.covariance.copy())
            history['sigma'].append(cma.sigma)
            history['fitness'].append(np.min(fitness_values))
        
        # å¯è§†åŒ–CMA-ESè¿‡ç¨‹
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=[
                "å‡å€¼è½¨è¿¹ä¸åæ–¹å·®æ¤­åœ†", "æ­¥é•¿æ¼”åŒ–",
                "é€‚åº”åº¦æ”¶æ•›", "ç‰¹å¾å€¼åˆ†æ"
            ]
        )
        
        # å‡å€¼è½¨è¿¹
        means = np.array(history['mean'])
        fig.add_trace(
            go.Scatter(
                x=means[:, 0], y=means[:, 1],
                mode='lines+markers',
                name='å‡å€¼è½¨è¿¹',
                line=dict(color='blue', width=2),
                marker=dict(size=4)
            ),
            row=1, col=1
        )
        
        # ç»˜åˆ¶åæ–¹å·®æ¤­åœ† (æ¯5æ­¥æ˜¾ç¤ºä¸€ä¸ª)
        for i in range(0, len(history['covariance']), 5):
            cov = history['covariance'][i]
            mean = history['mean'][i]
            
            # ç”Ÿæˆæ¤­åœ†ç‚¹
            theta = np.linspace(0, 2*np.pi, 50)
            eigenvals, eigenvecs = np.linalg.eig(cov)
            
            ellipse_points = []
            for t in theta:
                point = mean + 2 * history['sigma'][i] * (eigenvecs @ np.sqrt(eigenvals) * np.array([np.cos(t), np.sin(t)]))
                ellipse_points.append(point)
            
            ellipse_points = np.array(ellipse_points)
            
            fig.add_trace(
                go.Scatter(
                    x=ellipse_points[:, 0],
                    y=ellipse_points[:, 1],
                    mode='lines',
                    name=f'åæ–¹å·®æ¤­åœ† æ­¥éª¤{i}',
                    line=dict(width=1, color='gray'),
                    opacity=0.5,
                    showlegend=False
                ),
                row=1, col=1
            )
        
        # æ­¥é•¿æ¼”åŒ–
        fig.add_trace(
            go.Scatter(
                x=np.arange(len(history['sigma'])),
                y=history['sigma'],
                mode='lines',
                name='æ­¥é•¿',
                line=dict(color='red', width=2)
            ),
            row=1, col=2
        )
        
        # é€‚åº”åº¦æ”¶æ•›
        fig.add_trace(
            go.Scatter(
                x=np.arange(len(history['fitness'])),
                y=history['fitness'],
                mode='lines',
                name='æœ€ä½³é€‚åº”åº¦',
                line=dict(color='green', width=2)
            ),
            row=2, col=1
        )
        
        # ç‰¹å¾å€¼åˆ†æ
        eigenvalues_history = []
        for cov in history['covariance']:
            eigenvals = np.linalg.eigvals(cov)
            eigenvalues_history.append(sorted(eigenvals, reverse=True))
        
        eigenvalues_history = np.array(eigenvalues_history)
        
        fig.add_trace(
            go.Scatter(
                x=np.arange(len(eigenvalues_history)),
                y=eigenvalues_history[:, 0],
                mode='lines',
                name='æœ€å¤§ç‰¹å¾å€¼',
                line=dict(color='purple', width=2)
            ),
            row=2, col=2
        )
        
        fig.add_trace(
            go.Scatter(
                x=np.arange(len(eigenvalues_history)),
                y=eigenvalues_history[:, 1],
                mode='lines',
                name='æœ€å°ç‰¹å¾å€¼',
                line=dict(color='orange', width=2)
            ),
            row=2, col=2
        )
        
        fig.update_layout(
            title="CMA-ES åæ–¹å·®é€‚åº”è¿‡ç¨‹",
            height=600,
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # æœ€ç»ˆçŠ¶æ€åˆ†æ
        st.markdown("### ğŸ“Š æœ€ç»ˆçŠ¶æ€åˆ†æ")
        
        final_mean = history['mean'][-1]
        final_cov = history['covariance'][-1]
        final_sigma = history['sigma'][-1]
        final_fitness = history['fitness'][-1]
        
        eigenvals, eigenvecs = np.linalg.eig(final_cov)
        condition_number = max(eigenvals) / min(eigenvals)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æœ€ç»ˆé€‚åº”åº¦", f"{final_fitness:.4f}")
        with col2:
            st.metric("æœ€ç»ˆæ­¥é•¿", f"{final_sigma:.4f}")
        with col3:
            st.metric("æ¡ä»¶æ•°", f"{condition_number:.2f}")
        with col4:
            st.metric("è¿­ä»£æ¬¡æ•°", num_iterations)
        
        # åæ–¹å·®çŸ©é˜µå¯è§†åŒ–
        st.markdown("### ğŸ”„ åæ–¹å·®çŸ©é˜µæ¼”åŒ–")
        
        fig_cov = go.Figure()
        
        # çƒ­åŠ›å›¾æ˜¾ç¤ºæœ€ç»ˆåæ–¹å·®çŸ©é˜µ
        fig_cov.add_trace(
            go.Heatmap(
                z=final_cov,
                colorscale='RdBu',
                showscale=True,
                colorbar=dict(title="åæ–¹å·®å€¼")
            )
        )
        
        fig_cov.update_layout(
            title="æœ€ç»ˆåæ–¹å·®çŸ©é˜µ",
            xaxis_title="å‚æ•°ç»´åº¦",
            yaxis_title="å‚æ•°ç»´åº¦",
            height=400
        )
        
        st.plotly_chart(fig_cov, use_container_width=True)
        
        st.success("""
        **CMA-ES çš„æ ¸å¿ƒä¼˜åŠ¿**ï¼š
        - **æ¤­çƒæ¢ç´¢**ï¼šè‡ªé€‚åº”åæ–¹å·®çŸ©é˜µå®ç°æ¤­çƒæ¢ç´¢
        - **å‚æ•°ç›¸å…³æ€§**ï¼šè‡ªåŠ¨å­¦ä¹ å¹¶åˆ©ç”¨å‚æ•°é—´çš„ç›¸å…³æ€§
        - **è‡ªé€‚åº”æ€§**ï¼šæ­¥é•¿å’Œå½¢çŠ¶è‡ªåŠ¨è°ƒæ•´ï¼Œæ— éœ€æ‰‹åŠ¨è°ƒå‚
        - **æ•°å­¦ä¸¥è°¨æ€§**ï¼šåŸºäºè‡ªç„¶è¿›åŒ–ç­–ç•¥çš„ä¸¥æ ¼æ•°å­¦æ¨å¯¼
        """)


# ä¸ºäº†å…¼å®¹æ€§ï¼Œæ·»åŠ ç¼ºå°‘çš„å¯¼å…¥
try:
    from scipy.stats import multivariate_normal
except ImportError:
    # å¦‚æœscipyä¸å¯ç”¨ï¼Œä½¿ç”¨numpyå®ç°
    def multivariate_normal(mean, cov):
        class MVN:
            def rvs(self, size=1):
                return np.random.multivariate_normal(mean, cov, size)
        return MVN()

        # æ·»åŠ äº¤äº’å¼æµ‹éªŒ
