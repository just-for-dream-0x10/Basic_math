"""
äº¤äº’å¼å™ªå£°å¯è§†åŒ–
ä¸¥æ ¼æŒ‰ç…§ 9.noise.md ä¸­çš„ç†è®ºå®ç°
"""

import streamlit as st
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.linear_model import Ridge
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline


import sys
import os

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥commonæ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from common.error_handler import safe_render
from common.quiz_system import QuizSystem, QuizTemplates

class InteractiveNoise:
    """äº¤äº’å¼å™ªå£°ç†è®ºå¯è§†åŒ–"""
    
    @staticmethod
    @safe_render

    def render():
        st.subheader("ğŸ”Š äº¤äº’å¼å™ªå£°ç†è®º")
        st.markdown("""
        **å™ªå£° (Noise)**: æ•°æ®ä¸­ä¸å¯é¢„æµ‹çš„éšæœºæˆåˆ†
        
        **æ•°å­¦è¡¨ç¤º**: 
        $$Y = f(X) + \\epsilon$$
        
        å…¶ä¸­:
        - $Y$: è§‚æµ‹å€¼
        - $f(X)$: çœŸå®å‡½æ•°ï¼ˆç¡®å®šæ€§éƒ¨åˆ†ï¼‰
        - $\\epsilon$: å™ªå£°é¡¹ï¼Œ$\\mathbb{E}[\\epsilon] = 0$, $\\text{Var}(\\epsilon) = \\sigma^2$
        
        **æ ¸å¿ƒæ´å¯Ÿ**:
        - å™ªå£°ä¸æ˜¯è¿‡æ‹Ÿåˆçš„åŸå› ï¼Œè€Œæ˜¯èƒŒæ™¯å› ç´ 
        - æ¨¡å‹å¤æ‚åº¦å†³å®šæ˜¯å¦ä¼šæ‹Ÿåˆå™ªå£°
        - æ•°æ®é‡è¶Šå¤§ï¼Œå™ªå£°å½±å“è¶Šå°
        """)
        
        with st.sidebar:
            st.markdown("### ğŸ“Š é€‰æ‹©æ¼”ç¤º")
            demo_type = st.selectbox("æ¼”ç¤ºç±»å‹", [
                "å™ªå£°çš„æœ¬è´¨ç†è§£",
                "è¿‡æ‹Ÿåˆä¸å™ªå£°",
                "è®­ç»ƒè¯¯å·®vsæµ‹è¯•è¯¯å·®",
                "å­¦ä¹ æ›²çº¿åˆ†æ",
                "æ¨¡å‹å¤æ‚åº¦ä¸‰è§’å¹³è¡¡",
                "å™ªå£°é²æ£’æ€§ç­–ç•¥"
            ])
        
        if demo_type == "å™ªå£°çš„æœ¬è´¨ç†è§£":
            InteractiveNoise._render_noise_nature()
        elif demo_type == "è¿‡æ‹Ÿåˆä¸å™ªå£°":
            InteractiveNoise._render_overfitting()
        elif demo_type == "è®­ç»ƒè¯¯å·®vsæµ‹è¯•è¯¯å·®":
            InteractiveNoise._render_train_test_error()
        elif demo_type == "å­¦ä¹ æ›²çº¿åˆ†æ":
            InteractiveNoise._render_learning_curves()
        elif demo_type == "æ¨¡å‹å¤æ‚åº¦ä¸‰è§’å¹³è¡¡":
            InteractiveNoise._render_triangle_balance()
        elif demo_type == "å™ªå£°é²æ£’æ€§ç­–ç•¥":
            InteractiveNoise._render_robustness()
    

        # æ·»åŠ äº¤äº’å¼æµ‹éªŒ

        # æ·»åŠ äº¤äº’å¼æµ‹éªŒ
        quiz_system = QuizSystem("noise")
        quizzes = QuizTemplates.get_noise_quizzes()
        quiz_system.render_quiz(quizzes)
    @staticmethod
    def _render_noise_nature():
        """æ¼”ç¤ºå™ªå£°çš„æœ¬è´¨"""
        st.markdown("### ğŸ¯ å™ªå£°çš„æœ¬è´¨ç†è§£")
        st.markdown("""
        **å™ªå£° = ä»»ä½•ä¸èƒ½è¢«æ¨¡å‹æ•æ‰çš„ã€éšæœºçš„ã€ä¸å¯é¢„æµ‹çš„å˜åŒ–**
        
        è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç®€å•ä¾‹å­ç†è§£ï¼šå‡è®¾çœŸå®å…³ç³»æ˜¯ $y = 2x + 1$
        """)
        
        with st.sidebar:
            st.markdown("#### å‚æ•°è®¾ç½®")
            n_samples = st.slider("æ ·æœ¬æ•°é‡", 20, 200, 50, 10)
            noise_std = st.slider("å™ªå£°æ ‡å‡†å·® Ïƒ", 0.0, 5.0, 1.0, 0.1)
            show_true_function = st.checkbox("æ˜¾ç¤ºçœŸå®å‡½æ•°", True)
        
        # ç”Ÿæˆæ•°æ®
        np.random.seed(42)
        X = np.linspace(0, 10, n_samples)
        true_y = 2 * X + 1  # çœŸå®å‡½æ•°
        noise = np.random.normal(0, noise_std, n_samples)  # å™ªå£°
        observed_y = true_y + noise  # è§‚æµ‹å€¼
        
        # åˆ›å»ºå¯è§†åŒ–
        fig = go.Figure()
        
        # çœŸå®å‡½æ•°
        if show_true_function:
            fig.add_trace(go.Scatter(
                x=X, y=true_y,
                mode='lines',
                name='çœŸå®å‡½æ•° f(X) = 2X + 1',
                line=dict(color='green', width=3, dash='dash')
            ))
        
        # è§‚æµ‹æ•°æ®
        fig.add_trace(go.Scatter(
            x=X, y=observed_y,
            mode='markers',
            name='è§‚æµ‹å€¼ Y = f(X) + Îµ',
            marker=dict(color='blue', size=8, opacity=0.6)
        ))
        
        # å™ªå£°å¯è§†åŒ–ï¼ˆå‚ç›´çº¿ï¼‰
        for i in range(0, n_samples, max(1, n_samples // 20)):
            fig.add_trace(go.Scatter(
                x=[X[i], X[i]],
                y=[true_y[i], observed_y[i]],
                mode='lines',
                line=dict(color='red', width=1, dash='dot'),
                showlegend=(i == 0),
                name='å™ªå£° Îµ' if i == 0 else None
            ))
        
        fig.update_layout(
            title=f"å™ªå£°çš„æœ¬è´¨ï¼šY = f(X) + Îµ (Ïƒ = {noise_std:.1f})",
            xaxis_title="X",
            yaxis_title="Y",
            height=500,
            hovermode='closest',
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("å™ªå£°æ–¹å·® ÏƒÂ²", f"{noise_std**2:.2f}")
        with col2:
            st.metric("å®é™…å™ªå£°æ–¹å·®", f"{np.var(noise):.2f}")
        with col3:
            st.metric("ä¿¡å™ªæ¯” SNR", f"{np.var(true_y) / (noise_std**2 + 1e-10):.2f}")
        
        st.markdown("""
        **è§‚å¯Ÿ**:
        - ğŸŸ¢ ç»¿è‰²è™šçº¿ï¼šçœŸå®å‡½æ•°ï¼ˆç¡®å®šæ€§éƒ¨åˆ†ï¼‰
        - ğŸ”µ è“è‰²ç‚¹ï¼šå®é™…è§‚æµ‹åˆ°çš„æ•°æ®
        - ğŸ”´ çº¢è‰²è™šçº¿ï¼šå™ªå£°ï¼ˆåç¦»çœŸå®å€¼çš„éšæœºè¯¯å·®ï¼‰
        
        **å…³é”®ç†è§£**:
        1. å™ªå£°æ˜¯æ•°æ®ç”Ÿæˆè¿‡ç¨‹çš„ä¸€éƒ¨åˆ†ï¼Œæ— æ³•æ¶ˆé™¤
        2. å™ªå£°ä½¿å¾—å³ä½¿çŸ¥é“çœŸå®å‡½æ•°ï¼Œé¢„æµ‹ä¹Ÿä¸å¯èƒ½å®Œç¾
        3. $\\sigma^2$ æ˜¯æ¨¡å‹è¯¯å·®çš„ç†è®ºä¸‹ç•Œ
        """)
    
    @staticmethod
    def _render_overfitting():
        """æ¼”ç¤ºè¿‡æ‹Ÿåˆä¸å™ªå£°çš„å…³ç³»"""
        st.markdown("### ğŸª è¿‡æ‹Ÿåˆï¼šæ¨¡å‹å­¦ä¹ äº†å™ªå£°")
        st.markdown("""
        **æ ¸å¿ƒé—®é¢˜**: è¿‡æ‹Ÿåˆçš„åŸå› æ˜¯**æ¨¡å‹å¤ªå¤æ‚**ï¼Œè€Œéå™ªå£°æœ¬èº«
        
        **æ¯”å–»**: 
        - çœŸå®è§„å¾‹ = è€å¸ˆè®²çš„çŸ¥è¯†ç‚¹
        - å™ªå£° = è€å¸ˆçš„å£è¯¯ã€å’³å—½
        - è¿‡æ‹Ÿåˆ = å­¦ç”Ÿè¿å£è¯¯éƒ½èƒŒä¸‹æ¥äº†
        
        é—®é¢˜ä¸åœ¨å£è¯¯ï¼Œè€Œåœ¨å­¦ç”Ÿ"å¤ªè®¤çœŸ"ï¼ˆæ¨¡å‹å¤ªå¤æ‚ï¼‰
        """)
        
        with st.sidebar:
            st.markdown("#### å‚æ•°è®¾ç½®")
            noise_level = st.slider("å™ªå£°æ°´å¹³", 0.1, 3.0, 1.0, 0.1)
            model_degree = st.slider("å¤šé¡¹å¼é˜¶æ•°ï¼ˆæ¨¡å‹å¤æ‚åº¦ï¼‰", 1, 15, 3, 1)
            n_samples = st.slider("è®­ç»ƒæ ·æœ¬æ•°", 10, 100, 30, 10)
        
        # ç”Ÿæˆæ•°æ®
        np.random.seed(42)
        X_train = np.sort(np.random.uniform(0, 10, n_samples))
        true_y_train = np.sin(X_train) * 2  # çœŸå®å‡½æ•°ï¼šæ­£å¼¦æ³¢
        y_train = true_y_train + np.random.normal(0, noise_level, n_samples)
        
        # æµ‹è¯•æ•°æ®ï¼ˆå¯†é›†ï¼Œç”¨äºå¯è§†åŒ–ï¼‰
        X_test = np.linspace(0, 10, 200)
        true_y_test = np.sin(X_test) * 2
        
        # è®­ç»ƒæ¨¡å‹
        model = make_pipeline(PolynomialFeatures(model_degree), Ridge(alpha=0.01))
        model.fit(X_train.reshape(-1, 1), y_train)
        y_pred_train = model.predict(X_train.reshape(-1, 1))
        y_pred_test = model.predict(X_test.reshape(-1, 1))
        
        # è®¡ç®—è¯¯å·®
        train_error = np.mean((y_train - y_pred_train) ** 2)
        true_train_error = np.mean((true_y_train - y_pred_train) ** 2)
        test_error = np.mean((true_y_test - y_pred_test) ** 2)
        
        # å¯è§†åŒ–
        fig = go.Figure()
        
        # çœŸå®å‡½æ•°
        fig.add_trace(go.Scatter(
            x=X_test, y=true_y_test,
            mode='lines',
            name='çœŸå®å‡½æ•° f(X)',
            line=dict(color='green', width=3, dash='dash')
        ))
        
        # è®­ç»ƒæ•°æ®
        fig.add_trace(go.Scatter(
            x=X_train, y=y_train,
            mode='markers',
            name='è®­ç»ƒæ•°æ®ï¼ˆå«å™ªå£°ï¼‰',
            marker=dict(color='blue', size=10, symbol='circle')
        ))
        
        # æ¨¡å‹é¢„æµ‹
        fig.add_trace(go.Scatter(
            x=X_test, y=y_pred_test,
            mode='lines',
            name=f'æ¨¡å‹é¢„æµ‹ï¼ˆé˜¶æ•°={model_degree}ï¼‰',
            line=dict(color='red', width=2)
        ))
        
        fig.update_layout(
            title=f"è¿‡æ‹Ÿåˆæ¼”ç¤ºï¼šå¤šé¡¹å¼é˜¶æ•°={model_degree}",
            xaxis_title="X",
            yaxis_title="Y",
            height=500,
            hovermode='closest'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # è¯¯å·®åˆ†æ
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("è®­ç»ƒè¯¯å·®", f"{train_error:.4f}", 
                     help="æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šçš„MSE")
        with col2:
            st.metric("æµ‹è¯•è¯¯å·®", f"{test_error:.4f}",
                     help="æ¨¡å‹åœ¨çœŸå®å‡½æ•°ä¸Šçš„MSE")
        with col3:
            overfitting = test_error - train_error
            st.metric("è¿‡æ‹Ÿåˆç¨‹åº¦", f"{overfitting:.4f}",
                     delta=f"{overfitting:.4f}",
                     delta_color="inverse")
        
        # è¿‡æ‹Ÿåˆè¯Šæ–­
        if model_degree <= 3:
            st.success("âœ… æ¨¡å‹å¤æ‚åº¦é€‚ä¸­ï¼Œæ¬ æ‹Ÿåˆæˆ–åˆšå¥½")
        elif model_degree <= 7:
            st.warning("âš ï¸ æ¨¡å‹å¼€å§‹æ‹Ÿåˆå™ªå£°ï¼Œæ³¨æ„è¿‡æ‹Ÿåˆé£é™©")
        else:
            st.error("âŒ æ¨¡å‹ä¸¥é‡è¿‡æ‹Ÿåˆï¼Œå­¦ä¹ äº†è®­ç»ƒæ•°æ®ä¸­çš„å™ªå£°ï¼")
        
        st.markdown("""
        **å…³é”®è§‚å¯Ÿ**:
        1. **ä½é˜¶å¤šé¡¹å¼**ï¼ˆå¦‚1-3é˜¶ï¼‰ï¼šæ¨¡å‹å¤ªç®€å•ï¼Œæ¬ æ‹Ÿåˆï¼Œæ— æ³•å­¦ä¹ å™ªå£°
        2. **ä¸­é˜¶å¤šé¡¹å¼**ï¼ˆå¦‚4-7é˜¶ï¼‰ï¼šæ¨¡å‹é€‚ä¸­ï¼Œæ³›åŒ–è¾ƒå¥½
        3. **é«˜é˜¶å¤šé¡¹å¼**ï¼ˆå¦‚8-15é˜¶ï¼‰ï¼šæ¨¡å‹è¿‡äºå¤æ‚ï¼Œå¼€å§‹æ‹Ÿåˆå™ªå£°
        
        **ç»“è®º**: è¿‡æ‹Ÿåˆæ˜¯"æ¨¡å‹å®¹é‡è¿‡å‰©"çš„ç»“æœï¼Œå™ªå£°åªæ˜¯è¢«æ‹Ÿåˆçš„å¯¹è±¡
        """)
    
    @staticmethod
    def _render_train_test_error():
        """è®­ç»ƒè¯¯å·®vsæµ‹è¯•è¯¯å·®åˆ†æ"""
        st.markdown("### ğŸ“Š è®­ç»ƒè¯¯å·® vs æµ‹è¯•è¯¯å·®")
        st.markdown("""
        **æ ¸å¿ƒå…¬å¼**ï¼ˆæ¥è‡ªçº¿æ€§å›å½’ç†è®ºï¼‰ï¼š
        
        è®­ç»ƒè¯¯å·®æœŸæœ›ï¼š
        $$\\mathbb{E}[E_{\\text{in}}] = \\sigma^2 \\left(1 - \\frac{d+1}{N}\\right)$$
        
        æµ‹è¯•è¯¯å·®æœŸæœ›ï¼š
        $$\\mathbb{E}[E_{\\text{out}}] = \\sigma^2 \\left(1 + \\frac{d+1}{N}\\right)$$
        
        å…¶ä¸­ï¼š
        - $\\sigma^2$: å™ªå£°æ–¹å·®
        - $d$: æ¨¡å‹ç»´åº¦ï¼ˆå‚æ•°æ•°é‡-1ï¼‰
        - $N$: è®­ç»ƒæ ·æœ¬æ•°é‡
        """)
        
        with st.sidebar:
            st.markdown("#### å‚æ•°è®¾ç½®")
            noise_var = st.slider("å™ªå£°æ–¹å·® ÏƒÂ²", 0.1, 5.0, 1.0, 0.1)
            model_dim = st.slider("æ¨¡å‹ç»´åº¦ d", 1, 20, 5, 1)
            max_samples = st.slider("æœ€å¤§æ ·æœ¬æ•°", 50, 500, 200, 50)
        
        # æ ·æœ¬æ•°é‡èŒƒå›´
        N_range = np.arange(model_dim + 2, max_samples, 2)
        
        # è®¡ç®—ç†è®ºå€¼
        E_in_theory = noise_var * (1 - (model_dim + 1) / N_range)
        E_out_theory = noise_var * (1 + (model_dim + 1) / N_range)
        
        # åˆ›å»ºå¯è§†åŒ–
        fig = go.Figure()
        
        # å™ªå£°æ°´å¹³åŸºçº¿
        fig.add_hline(y=noise_var, 
                     line_dash="dash", 
                     line_color="gray",
                     annotation_text=f"å™ªå£°æ–¹å·® ÏƒÂ² = {noise_var}",
                     annotation_position="right")
        
        # è®­ç»ƒè¯¯å·®
        fig.add_trace(go.Scatter(
            x=N_range, y=E_in_theory,
            mode='lines',
            name='è®­ç»ƒè¯¯å·® E_in',
            line=dict(color='blue', width=3),
            fill='tonexty',
            fillcolor='rgba(59, 130, 246, 0.1)'
        ))
        
        # æµ‹è¯•è¯¯å·®
        fig.add_trace(go.Scatter(
            x=N_range, y=E_out_theory,
            mode='lines',
            name='æµ‹è¯•è¯¯å·® E_out',
            line=dict(color='red', width=3),
            fill='tonexty',
            fillcolor='rgba(239, 68, 68, 0.1)'
        ))
        
        # æ ‡æ³¨å…³é”®ç‚¹
        critical_n = model_dim * 10  # ä¸€èˆ¬è®¤ä¸º N = 10d æ˜¯æ¯”è¾ƒå¥½çš„ç‚¹
        if critical_n < max_samples:
            idx = np.argmin(np.abs(N_range - critical_n))
            fig.add_vline(x=N_range[idx],
                         line_dash="dot",
                         line_color="green",
                         annotation_text=f"N â‰ˆ 10d = {critical_n}",
                         annotation_position="top")
        
        fig.update_layout(
            title=f"è®­ç»ƒè¯¯å·® vs æµ‹è¯•è¯¯å·®éšæ ·æœ¬æ•°å˜åŒ– (d={model_dim}, ÏƒÂ²={noise_var})",
            xaxis_title="è®­ç»ƒæ ·æœ¬æ•°é‡ N",
            yaxis_title="è¯¯å·® (MSE)",
            height=500,
            hovermode='x unified',
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # å…³é”®æŒ‡æ ‡
        col1, col2, col3, col4 = st.columns(4)
        
        # æ‰¾åˆ° N=10d é™„è¿‘çš„å€¼
        target_n = model_dim * 10
        if target_n < max_samples:
            idx = np.argmin(np.abs(N_range - target_n))
            with col1:
                st.metric("å½“ N=10d æ—¶", f"N={N_range[idx]}")
            with col2:
                st.metric("è®­ç»ƒè¯¯å·®", f"{E_in_theory[idx]:.3f}")
            with col3:
                st.metric("æµ‹è¯•è¯¯å·®", f"{E_out_theory[idx]:.3f}")
            with col4:
                gap = E_out_theory[idx] - E_in_theory[idx]
                st.metric("æ³›åŒ–é—´éš™", f"{gap:.3f}")
        
        st.markdown("""
        **å…³é”®è§‚å¯Ÿ**:
        
        1. **è®­ç»ƒè¯¯å·® < å™ªå£°æ–¹å·®**: 
           - æ¨¡å‹å¯¹è®­ç»ƒé›†å™ªå£°è¿›è¡Œäº†æ‹Ÿåˆ
           - $E_{\\text{in}}$ ä»ä¸‹æ–¹é€¼è¿‘ $\\sigma^2$
        
        2. **æµ‹è¯•è¯¯å·® > å™ªå£°æ–¹å·®**: 
           - è®­ç»ƒé›†å™ªå£°çš„æ‹Ÿåˆæ— æ³•æ³›åŒ–
           - $E_{\\text{out}}$ ä»ä¸Šæ–¹é€¼è¿‘ $\\sigma^2$
        
        3. **éšç€ N å¢å¤§**:
           - ä¸¤è€…éƒ½æ”¶æ•›åˆ° $\\sigma^2$
           - æ³›åŒ–é—´éš™ $\\propto \\frac{d+1}{N}$
        
        4. **å½“ N â‰ˆ 10d æ—¶**:
           - é€šå¸¸è®¤ä¸ºæ˜¯è¾ƒå¥½çš„æ ·æœ¬é‡
           - æ¨¡å‹èƒ½è¾ƒå¥½åœ°å­¦ä¹ è§„å¾‹è€Œéå™ªå£°
        """)
    
    @staticmethod
    def _render_learning_curves():
        """å­¦ä¹ æ›²çº¿åˆ†æ"""
        st.markdown("### ğŸ“ˆ å­¦ä¹ æ›²çº¿ï¼šæ¨¡å‹å¦‚ä½•å­¦ä¹ ")
        st.markdown("""
        **å­¦ä¹ æ›²çº¿**å±•ç¤ºäº†éšç€è®­ç»ƒæ ·æœ¬å¢åŠ ï¼Œæ¨¡å‹æ€§èƒ½çš„å˜åŒ–
        
        **å…¸å‹å½¢æ€**:
        - è®­ç»ƒè¯¯å·® â†— é€æ¸ä¸Šå‡
        - æµ‹è¯•è¯¯å·® â†˜ é€æ¸ä¸‹é™
        - æœ€ç»ˆéƒ½æ”¶æ•›åˆ°å™ªå£°æ°´å¹³ $\\sigma^2$
        """)
        
        with st.sidebar:
            st.markdown("#### å‚æ•°è®¾ç½®")
            true_function = st.selectbox("çœŸå®å‡½æ•°", ["çº¿æ€§", "äºŒæ¬¡", "æ­£å¼¦"])
            noise_level = st.slider("å™ªå£°æ°´å¹³", 0.1, 2.0, 0.5, 0.1)
            model_complexity = st.slider("æ¨¡å‹å¤æ‚åº¦", 1, 10, 3, 1)
        
        # ç”ŸæˆçœŸå®å‡½æ•°
        def get_true_function(X, func_type):
            if func_type == "çº¿æ€§":
                return 2 * X + 1
            elif func_type == "äºŒæ¬¡":
                return 0.5 * X**2 - X + 1
            else:  # æ­£å¼¦
                return 2 * np.sin(X)
        
        # ä¸åŒæ ·æœ¬æ•°é‡ä¸‹çš„è¯¯å·®
        sample_sizes = np.arange(10, 201, 10)
        train_errors = []
        test_errors = []
        
        # å›ºå®šæµ‹è¯•é›†
        np.random.seed(42)
        X_test = np.linspace(0, 10, 200)
        y_test = get_true_function(X_test, true_function)
        
        for n in sample_sizes:
            # ç”Ÿæˆè®­ç»ƒæ•°æ®
            X_train = np.sort(np.random.uniform(0, 10, n))
            y_train_true = get_true_function(X_train, true_function)
            y_train = y_train_true + np.random.normal(0, noise_level, n)
            
            # è®­ç»ƒæ¨¡å‹
            model = make_pipeline(
                PolynomialFeatures(model_complexity), 
                Ridge(alpha=0.1)
            )
            model.fit(X_train.reshape(-1, 1), y_train)
            
            # è®¡ç®—è¯¯å·®
            y_pred_train = model.predict(X_train.reshape(-1, 1))
            y_pred_test = model.predict(X_test.reshape(-1, 1))
            
            train_errors.append(np.mean((y_train - y_pred_train)**2))
            test_errors.append(np.mean((y_test - y_pred_test)**2))
        
        # å¯è§†åŒ–
        fig = go.Figure()
        
        # å™ªå£°æ°´å¹³
        fig.add_hline(y=noise_level**2,
                     line_dash="dash",
                     line_color="gray",
                     annotation_text=f"å™ªå£°æ–¹å·® ÏƒÂ² = {noise_level**2:.2f}",
                     annotation_position="right")
        
        # è®­ç»ƒè¯¯å·®æ›²çº¿
        fig.add_trace(go.Scatter(
            x=sample_sizes, y=train_errors,
            mode='lines+markers',
            name='è®­ç»ƒè¯¯å·®',
            line=dict(color='blue', width=3),
            marker=dict(size=6)
        ))
        
        # æµ‹è¯•è¯¯å·®æ›²çº¿
        fig.add_trace(go.Scatter(
            x=sample_sizes, y=test_errors,
            mode='lines+markers',
            name='æµ‹è¯•è¯¯å·®',
            line=dict(color='red', width=3),
            marker=dict(size=6)
        ))
        
        # å¡«å……é—´éš™
        fig.add_trace(go.Scatter(
            x=list(sample_sizes) + list(sample_sizes[::-1]),
            y=list(train_errors) + list(test_errors[::-1]),
            fill='toself',
            fillcolor='rgba(255, 0, 0, 0.1)',
            line=dict(color='rgba(255,255,255,0)'),
            name='æ³›åŒ–é—´éš™',
            showlegend=True
        ))
        
        fig.update_layout(
            title=f"å­¦ä¹ æ›²çº¿ (æ¨¡å‹å¤æ‚åº¦={model_complexity}, å™ªå£°={noise_level})",
            xaxis_title="è®­ç»ƒæ ·æœ¬æ•°é‡",
            yaxis_title="å‡æ–¹è¯¯å·® (MSE)",
            height=500,
            hovermode='x unified'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # åˆ†æ
        final_train_error = train_errors[-1]
        final_test_error = test_errors[-1]
        final_gap = final_test_error - final_train_error
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æœ€ç»ˆè®­ç»ƒè¯¯å·®", f"{final_train_error:.3f}")
        with col2:
            st.metric("æœ€ç»ˆæµ‹è¯•è¯¯å·®", f"{final_test_error:.3f}")
        with col3:
            st.metric("æœ€ç»ˆæ³›åŒ–é—´éš™", f"{final_gap:.3f}")
        
        # è¯Šæ–­
        if final_gap > noise_level**2 * 0.5:
            st.warning("âš ï¸ æ³›åŒ–é—´éš™è¾ƒå¤§ï¼Œå¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆ")
        elif final_train_error > noise_level**2 * 2:
            st.warning("âš ï¸ è®­ç»ƒè¯¯å·®è¾ƒå¤§ï¼Œå¯èƒ½å­˜åœ¨æ¬ æ‹Ÿåˆ")
        else:
            st.success("âœ… æ¨¡å‹è®­ç»ƒè‰¯å¥½ï¼Œæ³›åŒ–æ€§èƒ½è¾ƒä¼˜")
        
        st.markdown("""
        **å­¦ä¹ æ›²çº¿è§£è¯»**:
        
        1. **åˆæœŸ** (æ ·æœ¬å°‘):
           - è®­ç»ƒè¯¯å·®å¾ˆä½ï¼ˆæ¨¡å‹è®°ä½äº†æ‰€æœ‰æ•°æ®ï¼‰
           - æµ‹è¯•è¯¯å·®å¾ˆé«˜ï¼ˆä¸¥é‡è¿‡æ‹Ÿåˆï¼‰
           - æ³›åŒ–é—´éš™å¾ˆå¤§
        
        2. **ä¸­æœŸ** (æ ·æœ¬å¢å¤š):
           - è®­ç»ƒè¯¯å·®ä¸Šå‡ï¼ˆæ— æ³•å®Œç¾æ‹Ÿåˆæ‰€æœ‰æ•°æ®ï¼‰
           - æµ‹è¯•è¯¯å·®ä¸‹é™ï¼ˆå­¦åˆ°äº†çœŸå®è§„å¾‹ï¼‰
           - æ³›åŒ–é—´éš™ç¼©å°
        
        3. **åæœŸ** (æ ·æœ¬å……è¶³):
           - ä¸¤æ¡æ›²çº¿æ”¶æ•›
           - éƒ½æ¥è¿‘å™ªå£°æ–¹å·® $\\sigma^2$
           - ç»§ç»­å¢åŠ æ•°æ®æ”¶ç›Šé€’å‡
        """)
    
    @staticmethod
    def _render_triangle_balance():
        """æ¨¡å‹å¤æ‚åº¦ã€æ•°æ®é‡ã€å™ªå£°çš„ä¸‰è§’å¹³è¡¡"""
        st.markdown("### âš–ï¸ å­¦ä¹ çš„ä¸‰è§’å¹³è¡¡")
        st.markdown("""
        **æ³›åŒ–è¯¯å·®åˆ†è§£**ï¼ˆç®€åŒ–ç‰ˆï¼‰:
        
        $$R \\approx R_{\\text{emp}} + \\sqrt{\\frac{d_{VC}}{N}} + \\sigma^2$$
        
        | è¦ç´  | å½±å“ | æ§åˆ¶æ‰‹æ®µ |
        |------|------|----------|
        | æ¨¡å‹å¤æ‚åº¦ $d$ | å®¹é‡è¶Šå¤§ï¼Œè¶Šå®¹æ˜“è¿‡æ‹Ÿåˆ | æ­£åˆ™åŒ–ã€å‰ªæã€æ—©åœ |
        | æ•°æ®é‡ $N$ | æ•°æ®è¶Šå¤šï¼Œæ³›åŒ–è¶Šå¥½ | æ•°æ®å¢å¼ºã€ä¸»åŠ¨å­¦ä¹  |
        | å™ªå£° $\\sigma^2$ | æ€§èƒ½ä¸‹ç•Œ | æ•°æ®æ¸…æ´—ã€é²æ£’æŸå¤± |
        """)
        
        with st.sidebar:
            st.markdown("#### å‚æ•°è®¾ç½®")
            vc_dim = st.slider("VCç»´ d", 1, 50, 10, 1)
            sample_size = st.slider("æ ·æœ¬æ•° N", 10, 1000, 100, 10)
            noise_var = st.slider("å™ªå£°æ–¹å·® ÏƒÂ²", 0.1, 5.0, 1.0, 0.1)
        
        # è®¡ç®—æ³›åŒ–è¯¯å·®çš„å„ä¸ªç»„æˆéƒ¨åˆ†
        empirical_risk = 0.1  # å‡è®¾ç»éªŒé£é™©å¾ˆå°
        complexity_penalty = np.sqrt(vc_dim / sample_size)
        noise_bound = noise_var
        total_risk = empirical_risk + complexity_penalty + noise_bound
        
        # åˆ›å»ºé¥¼å›¾
        fig = go.Figure(data=[go.Pie(
            labels=['ç»éªŒé£é™©', 'å¤æ‚åº¦æƒ©ç½š', 'å™ªå£°ä¸‹ç•Œ'],
            values=[empirical_risk, complexity_penalty, noise_bound],
            marker=dict(colors=['#3B82F6', '#F59E0B', '#EF4444']),
            hole=0.3,
            textinfo='label+percent',
            textposition='outside'
        )])
        
        fig.update_layout(
            title=f"æ³›åŒ–è¯¯å·®åˆ†è§£ (d={vc_dim}, N={sample_size}, ÏƒÂ²={noise_var})",
            height=500,
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # æŒ‡æ ‡å±•ç¤º
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ç»éªŒé£é™©", f"{empirical_risk:.3f}")
        with col2:
            st.metric("å¤æ‚åº¦æƒ©ç½š", f"{complexity_penalty:.3f}")
        with col3:
            st.metric("å™ªå£°ä¸‹ç•Œ", f"{noise_bound:.3f}")
        with col4:
            st.metric("æ€»æ³›åŒ–è¯¯å·®", f"{total_risk:.3f}")
        
        # æ¯”ä¾‹åˆ†æ
        st.markdown("#### ğŸ“Š è¯¯å·®æ¥æºåˆ†æ")
        
        complexity_ratio = complexity_penalty / total_risk
        noise_ratio = noise_bound / total_risk
        
        if noise_ratio > 0.6:
            st.info(f"ğŸ”Š **å™ªå£°ä¸»å¯¼** ({noise_ratio*100:.1f}%): æ•°æ®è´¨é‡æ˜¯ä¸»è¦ç“¶é¢ˆï¼Œè€ƒè™‘æ•°æ®æ¸…æ´—æˆ–é²æ£’æ–¹æ³•")
        elif complexity_ratio > 0.4:
            st.warning(f"ğŸ“ **å¤æ‚åº¦ä¸»å¯¼** ({complexity_ratio*100:.1f}%): æ¨¡å‹è¿‡äºå¤æ‚æˆ–æ•°æ®ä¸è¶³ï¼Œè€ƒè™‘æ­£åˆ™åŒ–æˆ–å¢åŠ æ•°æ®")
        else:
            st.success("âœ… **å¹³è¡¡çŠ¶æ€**: æ¨¡å‹ã€æ•°æ®ã€å™ªå£°ä¸‰è€…è¾ƒä¸ºå¹³è¡¡")
        
        # å»ºè®®
        st.markdown("#### ğŸ’¡ ä¼˜åŒ–å»ºè®®")
        
        suggestions = []
        
        if vc_dim / sample_size > 0.1:
            suggestions.append("âš ï¸ **æ ·æœ¬ä¸è¶³**: $N/d$ æ¯”ä¾‹è¾ƒä½ï¼Œå»ºè®®å¢åŠ æ•°æ®é‡æˆ–é™ä½æ¨¡å‹å¤æ‚åº¦")
        
        if noise_var > 2.0:
            suggestions.append("ğŸ”Š **å™ªå£°è¿‡å¤§**: è€ƒè™‘æ•°æ®æ¸…æ´—ã€ç‰¹å¾å·¥ç¨‹æˆ–ä½¿ç”¨é²æ£’æŸå¤±å‡½æ•°")
        
        if sample_size < vc_dim * 10:
            suggestions.append("ğŸ“Š **ç»éªŒæ³•åˆ™**: é€šå¸¸å»ºè®® $N \\geq 10d$ï¼Œå½“å‰ $N/d = {:.1f}$".format(sample_size/vc_dim))
        
        if len(suggestions) == 0:
            st.success("âœ… å½“å‰é…ç½®åˆç†ï¼Œç»§ç»­ä¿æŒï¼")
        else:
            for sugg in suggestions:
                st.markdown(sugg)
    
    @staticmethod
    def _render_robustness():
        """å™ªå£°é²æ£’æ€§ç­–ç•¥"""
        st.markdown("### ğŸ›¡ï¸ å™ªå£°é²æ£’æ€§ç­–ç•¥")
        st.markdown("""
        **ç›®æ ‡**: è®©æ¨¡å‹"å­¦ä¼šè·³è¿‡"å™ªå£°ï¼Œåªå­¦ä¹ çœŸå®è§„å¾‹
        
        **æ ¸å¿ƒç­–ç•¥**:
        1. **æ­£åˆ™åŒ–** (L1/L2): é™åˆ¶æ¨¡å‹å¤æ‚åº¦
        2. **æ—©åœ** (Early Stopping): é˜²æ­¢è¿‡åº¦è®­ç»ƒ
        3. **Dropout**: éšæœºå¤±æ´»ï¼Œå¢å¼ºæ³›åŒ–
        4. **æ•°æ®å¢å¼º**: å¢åŠ æ ·æœ¬å¤šæ ·æ€§
        5. **é²æ£’æŸå¤±**: å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿ
        """)
        
        with st.sidebar:
            st.markdown("#### å‚æ•°è®¾ç½®")
            strategy = st.selectbox("é€‰æ‹©ç­–ç•¥", [
                "æ­£åˆ™åŒ–æ•ˆæœ",
                "æ—©åœæ¼”ç¤º",
                "é²æ£’æŸå¤±å¯¹æ¯”"
            ])
        
        if strategy == "æ­£åˆ™åŒ–æ•ˆæœ":
            InteractiveNoise._render_regularization_effect()
        elif strategy == "æ—©åœæ¼”ç¤º":
            InteractiveNoise._render_early_stopping()
        else:
            InteractiveNoise._render_robust_loss()
    
    @staticmethod
    def _render_regularization_effect():
        """æ­£åˆ™åŒ–æ•ˆæœæ¼”ç¤º"""
        st.markdown("#### ğŸ¯ æ­£åˆ™åŒ–ï¼šé™åˆ¶æ¨¡å‹å¤æ‚åº¦")
        
        with st.sidebar:
            noise_level = st.slider("å™ªå£°æ°´å¹³", 0.1, 2.0, 0.8, 0.1)
            alpha = st.slider("æ­£åˆ™åŒ–å¼ºåº¦ Î±", 0.0, 10.0, 1.0, 0.1)
            n_samples = st.slider("è®­ç»ƒæ ·æœ¬", 20, 100, 30, 10)
        
        # ç”Ÿæˆæ•°æ®
        np.random.seed(42)
        X_train = np.sort(np.random.uniform(0, 10, n_samples))
        true_y = np.sin(X_train) * 2
        y_train = true_y + np.random.normal(0, noise_level, n_samples)
        
        X_test = np.linspace(0, 10, 200)
        y_test_true = np.sin(X_test) * 2
        
        # è®­ç»ƒä¸‰ä¸ªæ¨¡å‹ï¼šæ— æ­£åˆ™åŒ–ã€å¼±æ­£åˆ™åŒ–ã€å¼ºæ­£åˆ™åŒ–
        models = {
            'æ— æ­£åˆ™åŒ– (Î±=0)': Ridge(alpha=0.001),
            f'é€‚åº¦æ­£åˆ™åŒ– (Î±={alpha})': Ridge(alpha=alpha),
            'å¼ºæ­£åˆ™åŒ– (Î±=10)': Ridge(alpha=10.0)
        }
        
        fig = go.Figure()
        
        # çœŸå®å‡½æ•°
        fig.add_trace(go.Scatter(
            x=X_test, y=y_test_true,
            mode='lines',
            name='çœŸå®å‡½æ•°',
            line=dict(color='green', width=3, dash='dash')
        ))
        
        # è®­ç»ƒæ•°æ®
        fig.add_trace(go.Scatter(
            x=X_train, y=y_train,
            mode='markers',
            name='è®­ç»ƒæ•°æ®',
            marker=dict(color='gray', size=8, opacity=0.5)
        ))
        
        colors = ['red', 'blue', 'orange']
        train_errors = []
        test_errors = []
        
        for (name, model), color in zip(models.items(), colors):
            # ä½¿ç”¨é«˜é˜¶å¤šé¡¹å¼
            poly_model = make_pipeline(PolynomialFeatures(10), model)
            poly_model.fit(X_train.reshape(-1, 1), y_train)
            
            y_pred = poly_model.predict(X_test.reshape(-1, 1))
            
            fig.add_trace(go.Scatter(
                x=X_test, y=y_pred,
                mode='lines',
                name=name,
                line=dict(color=color, width=2)
            ))
            
            # è®¡ç®—è¯¯å·®
            train_pred = poly_model.predict(X_train.reshape(-1, 1))
            train_errors.append(np.mean((y_train - train_pred)**2))
            test_errors.append(np.mean((y_test_true - y_pred)**2))
        
        fig.update_layout(
            title="æ­£åˆ™åŒ–æ•ˆæœå¯¹æ¯”",
            xaxis_title="X",
            yaxis_title="Y",
            height=500,
            hovermode='closest'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # è¯¯å·®å¯¹æ¯”
        st.markdown("#### ğŸ“Š è¯¯å·®å¯¹æ¯”")
        
        col1, col2, col3 = st.columns(3)
        for i, (name, _) in enumerate(models.items()):
            with [col1, col2, col3][i]:
                st.metric(name, f"æµ‹è¯•è¯¯å·®: {test_errors[i]:.3f}")
                st.caption(f"è®­ç»ƒè¯¯å·®: {train_errors[i]:.3f}")
        
        st.markdown("""
        **è§‚å¯Ÿ**:
        - ğŸ”´ **æ— æ­£åˆ™åŒ–**: ä¸¥é‡è¿‡æ‹Ÿåˆï¼Œæ›²çº¿å‰§çƒˆéœ‡è¡
        - ğŸ”µ **é€‚åº¦æ­£åˆ™åŒ–**: å¹³æ»‘æ›²çº¿ï¼Œæ³›åŒ–æœ€å¥½
        - ğŸŸ  **å¼ºæ­£åˆ™åŒ–**: æ›²çº¿è¿‡äºå¹³æ»‘ï¼Œå¯èƒ½æ¬ æ‹Ÿåˆ
        
        **ç»“è®º**: æ­£åˆ™åŒ–é€šè¿‡æƒ©ç½šæ¨¡å‹å¤æ‚åº¦ï¼Œè¿«ä½¿æ¨¡å‹å¿½ç•¥å™ªå£°
        """)
    
    @staticmethod
    def _render_early_stopping():
        """æ—©åœæ¼”ç¤º"""
        st.markdown("#### â±ï¸ æ—©åœï¼šåœ¨åˆé€‚çš„æ—¶æœºåœæ­¢è®­ç»ƒ")
        
        st.markdown("""
        **åŸç†**: ç›‘æ§éªŒè¯é›†è¯¯å·®ï¼Œå½“å…¶ä¸å†ä¸‹é™æ—¶åœæ­¢è®­ç»ƒ
        
        **ç±»æ¯”**: å­¦ç”Ÿåšé¢˜ï¼Œåšåˆ°ä¸€å®šç¨‹åº¦å°±å¤Ÿäº†ï¼Œç»§ç»­åšåè€Œä¼š"èƒŒé¢˜"
        """)
        
        with st.sidebar:
            noise_level = st.slider("å™ªå£°æ°´å¹³", 0.1, 2.0, 0.5, 0.1)
            max_epochs = st.slider("æœ€å¤§è®­ç»ƒè½®æ•°", 50, 500, 200, 50)
        
        # ç”Ÿæˆæ•°æ®
        np.random.seed(42)
        n_train = 50
        X_train = np.sort(np.random.uniform(0, 10, n_train))
        true_y_train = np.sin(X_train) * 2
        y_train = true_y_train + np.random.normal(0, noise_level, n_train)
        
        X_val = np.sort(np.random.uniform(0, 10, 30))
        true_y_val = np.sin(X_val) * 2
        y_val = true_y_val + np.random.normal(0, noise_level, 30)
        
        # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹ï¼ˆé€šè¿‡å¢åŠ æ¨¡å‹å¤æ‚åº¦æ¨¡æ‹Ÿè®­ç»ƒï¼‰
        epochs = np.arange(1, max_epochs + 1)
        train_errors = []
        val_errors = []
        
        for epoch in epochs:
            # å¤æ‚åº¦éšepochå¢åŠ 
            degree = min(1 + epoch // 20, 15)
            model = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0.01))
            model.fit(X_train.reshape(-1, 1), y_train)
            
            train_pred = model.predict(X_train.reshape(-1, 1))
            val_pred = model.predict(X_val.reshape(-1, 1))
            
            train_errors.append(np.mean((y_train - train_pred)**2))
            val_errors.append(np.mean((y_val - val_pred)**2))
        
        # æ‰¾åˆ°æœ€ä½³åœæ­¢ç‚¹ï¼ˆéªŒè¯è¯¯å·®æœ€å°ï¼‰
        best_epoch = np.argmin(val_errors) + 1
        
        # å¯è§†åŒ–
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=epochs, y=train_errors,
            mode='lines',
            name='è®­ç»ƒè¯¯å·®',
            line=dict(color='blue', width=2)
        ))
        
        fig.add_trace(go.Scatter(
            x=epochs, y=val_errors,
            mode='lines',
            name='éªŒè¯è¯¯å·®',
            line=dict(color='red', width=2)
        ))
        
        # æ ‡æ³¨æœ€ä½³åœæ­¢ç‚¹
        fig.add_vline(x=best_epoch,
                     line_dash="dash",
                     line_color="green",
                     annotation_text=f"æœ€ä½³åœæ­¢ç‚¹ (epoch={best_epoch})",
                     annotation_position="top")
        
        # æ ‡æ³¨è¿‡æ‹ŸåˆåŒºåŸŸ
        fig.add_vrect(x0=best_epoch, x1=max_epochs,
                     fillcolor="red", opacity=0.1,
                     annotation_text="è¿‡æ‹ŸåˆåŒºåŸŸ",
                     annotation_position="top right")
        
        fig.update_layout(
            title="æ—©åœæ¼”ç¤ºï¼šè®­ç»ƒè¯¯å·® vs éªŒè¯è¯¯å·®",
            xaxis_title="è®­ç»ƒè½®æ•° (Epoch)",
            yaxis_title="è¯¯å·® (MSE)",
            height=500,
            hovermode='x unified'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æœ€ä½³åœæ­¢ç‚¹", f"Epoch {best_epoch}")
        with col2:
            st.metric("æœ€ä½³éªŒè¯è¯¯å·®", f"{val_errors[best_epoch-1]:.4f}")
        with col3:
            final_val_error = val_errors[-1]
            improvement = final_val_error - val_errors[best_epoch-1]
            st.metric("è¿‡æ‹ŸåˆæŸå¤±", f"+{improvement:.4f}", 
                     delta=f"{improvement:.4f}", delta_color="inverse")
        
        st.markdown("""
        **å…³é”®è§‚å¯Ÿ**:
        
        1. **åˆæœŸ**: è®­ç»ƒè¯¯å·®å’ŒéªŒè¯è¯¯å·®éƒ½ä¸‹é™ï¼ˆå­¦ä¹ è§„å¾‹ï¼‰
        2. **æœ€ä½³ç‚¹**: éªŒè¯è¯¯å·®è¾¾åˆ°æœ€å°å€¼
        3. **è¿‡æ‹ŸåˆåŒº**: è®­ç»ƒè¯¯å·®ç»§ç»­ä¸‹é™ï¼ŒéªŒè¯è¯¯å·®ä¸Šå‡ï¼ˆå­¦ä¹ å™ªå£°ï¼‰
        
        **ç­–ç•¥**: åœ¨éªŒè¯è¯¯å·®ä¸å†æ”¹å–„æ—¶ï¼ˆé€šå¸¸è§‚å¯Ÿ5-10ä¸ªepochï¼‰ï¼Œåœæ­¢è®­ç»ƒ
        """)
    
    @staticmethod
    def _render_robust_loss():
        """é²æ£’æŸå¤±å‡½æ•°å¯¹æ¯”"""
        st.markdown("#### ğŸ“ é²æ£’æŸå¤±ï¼šå¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿ")
        
        st.markdown("""
        **é—®é¢˜**: å¹³æ–¹æŸå¤± (MSE) å¯¹å¼‚å¸¸å€¼éå¸¸æ•æ„Ÿ
        
        **è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨é²æ£’æŸå¤±å‡½æ•°
        - **Huber Loss**: åœ¨å°è¯¯å·®æ—¶ç”¨L2ï¼Œå¤§è¯¯å·®æ—¶ç”¨L1
        - **MAE (L1)**: å¯¹æ‰€æœ‰è¯¯å·®çº¿æ€§æƒ©ç½š
        """)
        
        with st.sidebar:
            delta = st.slider("Huber Î´ å‚æ•°", 0.5, 5.0, 1.0, 0.5)
            outlier_ratio = st.slider("å¼‚å¸¸å€¼æ¯”ä¾‹", 0.0, 0.3, 0.1, 0.05)
        
        # ç”Ÿæˆè¯¯å·®èŒƒå›´
        errors = np.linspace(-5, 5, 200)
        
        # ä¸åŒæŸå¤±å‡½æ•°
        mse_loss = errors ** 2
        mae_loss = np.abs(errors)
        huber_loss = np.where(
            np.abs(errors) <= delta,
            0.5 * errors ** 2,
            delta * np.abs(errors) - 0.5 * delta ** 2
        )
        
        # å¯è§†åŒ–æŸå¤±å‡½æ•°
        fig = make_subplots(rows=1, cols=2,
                           subplot_titles=("æŸå¤±å‡½æ•°å¯¹æ¯”", "å¯¹å¼‚å¸¸å€¼çš„å½±å“"))
        
        # å·¦å›¾ï¼šæŸå¤±å‡½æ•°æ›²çº¿
        fig.add_trace(go.Scatter(
            x=errors, y=mse_loss,
            mode='lines',
            name='MSE (L2)',
            line=dict(color='red', width=2)
        ), row=1, col=1)
        
        fig.add_trace(go.Scatter(
            x=errors, y=mae_loss,
            mode='lines',
            name='MAE (L1)',
            line=dict(color='blue', width=2)
        ), row=1, col=1)
        
        fig.add_trace(go.Scatter(
            x=errors, y=huber_loss,
            mode='lines',
            name=f'Huber (Î´={delta})',
            line=dict(color='green', width=2)
        ), row=1, col=1)
        
        # å³å›¾ï¼šå®é™…æ•°æ®ç¤ºä¾‹
        np.random.seed(42)
        n_samples = 50
        X = np.linspace(0, 10, n_samples)
        y_true = 2 * X + 1
        y_noisy = y_true + np.random.normal(0, 0.5, n_samples)
        
        # æ·»åŠ å¼‚å¸¸å€¼
        n_outliers = int(n_samples * outlier_ratio)
        outlier_idx = np.random.choice(n_samples, n_outliers, replace=False)
        y_noisy[outlier_idx] += np.random.normal(0, 5, n_outliers)
        
        fig.add_trace(go.Scatter(
            x=X, y=y_true,
            mode='lines',
            name='çœŸå®å‡½æ•°',
            line=dict(color='green', width=3, dash='dash'),
            showlegend=False
        ), row=1, col=2)
        
        # æ­£å¸¸ç‚¹
        normal_mask = np.ones(n_samples, dtype=bool)
        normal_mask[outlier_idx] = False
        
        fig.add_trace(go.Scatter(
            x=X[normal_mask], y=y_noisy[normal_mask],
            mode='markers',
            name='æ­£å¸¸æ•°æ®',
            marker=dict(color='blue', size=6),
            showlegend=False
        ), row=1, col=2)
        
        # å¼‚å¸¸ç‚¹
        fig.add_trace(go.Scatter(
            x=X[outlier_idx], y=y_noisy[outlier_idx],
            mode='markers',
            name='å¼‚å¸¸å€¼',
            marker=dict(color='red', size=10, symbol='x'),
            showlegend=False
        ), row=1, col=2)
        
        fig.update_xaxes(title_text="è¯¯å·®", row=1, col=1)
        fig.update_xaxes(title_text="X", row=1, col=2)
        fig.update_yaxes(title_text="æŸå¤±", row=1, col=1)
        fig.update_yaxes(title_text="Y", row=1, col=2)
        
        fig.update_layout(height=500, showlegend=True)
        
        st.plotly_chart(fig, use_container_width=True)
        
        # è®¡ç®—ä¸åŒæŸå¤±ä¸‹çš„æ€»æŸå¤±
        residuals = y_noisy - y_true
        total_mse = np.mean(residuals ** 2)
        total_mae = np.mean(np.abs(residuals))
        total_huber = np.mean(np.where(
            np.abs(residuals) <= delta,
            0.5 * residuals ** 2,
            delta * np.abs(residuals) - 0.5 * delta ** 2
        ))
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("MSEæŸå¤±", f"{total_mse:.3f}", 
                     help="å¯¹å¼‚å¸¸å€¼éå¸¸æ•æ„Ÿ")
        with col2:
            st.metric("MAEæŸå¤±", f"{total_mae:.3f}",
                     help="å¯¹å¼‚å¸¸å€¼é²æ£’ï¼Œä½†ä¼˜åŒ–å›°éš¾")
        with col3:
            st.metric("HuberæŸå¤±", f"{total_huber:.3f}",
                     help="å¹³è¡¡äº†MSEå’ŒMAEçš„ä¼˜ç‚¹")
        
        st.markdown("""
        **æŸå¤±å‡½æ•°ç‰¹ç‚¹**:
        
        | æŸå¤±å‡½æ•° | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
        |---------|------|------|----------|
        | **MSE (L2)** | å¯å¾®ã€ä¼˜åŒ–å®¹æ˜“ | å¯¹å¼‚å¸¸å€¼æ•æ„Ÿ | æ•°æ®å¹²å‡€æ—¶ |
        | **MAE (L1)** | å¯¹å¼‚å¸¸å€¼é²æ£’ | ä¸å¯å¾®ã€ä¼˜åŒ–å›°éš¾ | å¤§é‡å¼‚å¸¸å€¼ |
        | **Huber** | å…¼å…·ä¸¤è€…ä¼˜ç‚¹ | éœ€è¦è°ƒå‚Î´ | å°‘é‡å¼‚å¸¸å€¼ |
        
        **ç»“è®º**: 
        - å½“æ•°æ®åŒ…å«å¼‚å¸¸å€¼æˆ–æ ‡ç­¾å™ªå£°æ—¶ï¼Œä½¿ç”¨é²æ£’æŸå¤±
        - HuberæŸå¤±æ˜¯å®è·µä¸­å¸¸ç”¨çš„æŠ˜ä¸­æ–¹æ¡ˆ
        - æ ¹æ®å¼‚å¸¸å€¼çš„ä¸¥é‡ç¨‹åº¦è°ƒæ•´Î´å‚æ•°
        """)
