"""
åˆ†ç±»æ¨¡å‹çš„æœ¬è´¨ä¼˜åŒ–é€»è¾‘ - äº¤äº’å¼å¯è§†åŒ–
åŸºäº 8.TheEssentialOptimizationLogicOfClassificationModels.md

æ ¸å¿ƒå†…å®¹ï¼š
1. ä¸‰ç§ä¼˜åŒ–æ€è·¯çš„ç»Ÿä¸€æ¡†æ¶
2. æœ€å°äºŒä¹˜æ³• (Least Squares)
3. æœ€å¤§ä¼¼ç„¶ä¼°è®¡ (Maximum Likelihood)
4. SVM é—´éš”æœ€å¤§åŒ–
5. æŸå¤±å‡½æ•°å¯¹æ¯”
6. å†³ç­–è¾¹ç•Œæ¼”åŒ–
"""

import streamlit as st
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.svm import SVC
from sklearn.datasets import make_classification, make_blobs


import sys
import os

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥commonæ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from common.error_handler import safe_render
from common.quiz_system import QuizSystem, QuizTemplates

class InteractiveClassificationOptimization:
    """äº¤äº’å¼åˆ†ç±»ä¼˜åŒ–é€»è¾‘å¯è§†åŒ–"""
    
    @staticmethod
    @safe_render

    def render():
        st.subheader("ğŸ¯ åˆ†ç±»æ¨¡å‹çš„æœ¬è´¨ä¼˜åŒ–é€»è¾‘")
        
        st.markdown(r"""
        **æ ¸å¿ƒé—®é¢˜**: å¦‚ä½•è®©æ¨¡å‹è¾“å‡º $G(X)$ çœ‹é½çœŸå®æ ‡ç­¾ $T(X)$ï¼Ÿ
        
        **ä¸‰ç§ç»å…¸æ€è·¯**:
        1. **æœ€å°äºŒä¹˜æ³•** - æ•°å€¼æ‹Ÿåˆè§†è§’
        2. **æœ€å¤§ä¼¼ç„¶ä¼°è®¡** - æ¦‚ç‡ç»Ÿè®¡è§†è§’
        3. **SVM** - å‡ ä½•é—´éš”è§†è§’
        """)
        
        with st.sidebar:
            st.markdown("### ğŸ“Š é€‰æ‹©æ¼”ç¤º")
            demo_type = st.selectbox(
                "æ¼”ç¤ºç±»å‹",
                [
                    "ä¸‰ç§æ–¹æ³•ç»Ÿä¸€å¯¹æ¯”",
                    "æœ€å°äºŒä¹˜æ³• (LSE)",
                    "æœ€å¤§ä¼¼ç„¶ä¼°è®¡ (MLE)",
                    "SVMé—´éš”æœ€å¤§åŒ–",
                    "æŸå¤±å‡½æ•°å¯¹æ¯”",
                    "å†³ç­–è¾¹ç•Œæ¼”åŒ–",
                    "å®æˆ˜æ¡ˆä¾‹"
                ]
            )
        
        if demo_type == "ä¸‰ç§æ–¹æ³•ç»Ÿä¸€å¯¹æ¯”":
            InteractiveClassificationOptimization._render_unified_comparison()
        elif demo_type == "æœ€å°äºŒä¹˜æ³• (LSE)":
            InteractiveClassificationOptimization._render_least_squares()
        elif demo_type == "æœ€å¤§ä¼¼ç„¶ä¼°è®¡ (MLE)":
            InteractiveClassificationOptimization._render_mle()
        elif demo_type == "SVMé—´éš”æœ€å¤§åŒ–":
            InteractiveClassificationOptimization._render_svm()
        elif demo_type == "æŸå¤±å‡½æ•°å¯¹æ¯”":
            InteractiveClassificationOptimization._render_loss_comparison()
        elif demo_type == "å†³ç­–è¾¹ç•Œæ¼”åŒ–":
            InteractiveClassificationOptimization._render_boundary_evolution()
        elif demo_type == "å®æˆ˜æ¡ˆä¾‹":
            InteractiveClassificationOptimization._render_practical_case()
    

        # æ·»åŠ äº¤äº’å¼æµ‹éªŒ

        # æ·»åŠ äº¤äº’å¼æµ‹éªŒ
        quiz_system = QuizSystem("classification_optimization")
        quizzes = QuizTemplates.get_classification_optimization_quizzes()
        quiz_system.render_quiz(quizzes)
    @staticmethod
    def _generate_binary_data(n_samples=100, noise=0.1, random_state=42):
        """ç”ŸæˆäºŒåˆ†ç±»æ•°æ®"""
        np.random.seed(random_state)
        X, y = make_classification(
            n_samples=n_samples,
            n_features=2,
            n_redundant=0,
            n_informative=2,
            n_clusters_per_class=1,
            flip_y=noise,
            random_state=random_state
        )
        # è½¬æ¢æ ‡ç­¾ä¸º {-1, 1}
        y = 2 * y - 1
        return X, y
    
    @staticmethod
    def _render_unified_comparison():
        """ä¸‰ç§æ–¹æ³•çš„ç»Ÿä¸€å¯¹æ¯”"""
        st.markdown("### ğŸ”„ ä¸‰ç§æ–¹æ³•çš„ç»Ÿä¸€æ¡†æ¶")
        
        st.markdown(r"""
        **ç›¸åŒçš„ç›®æ ‡ï¼Œä¸åŒçš„è§†è§’**ï¼š
        
        | æ–¹é¢ | æœ€å°äºŒä¹˜æ³• | æœ€å¤§ä¼¼ç„¶ä¼°è®¡ | SVM |
        |------|------------|--------------|-----|
        | **åº¦é‡æ„ä¹‰** | æ•°å€¼æ‹Ÿåˆ | æ¦‚ç‡è§£é‡Š | å‡ ä½•è·ç¦» |
        | **æŸå¤±å‡½æ•°** | MSE | Cross-Entropy | Hinge Loss |
        | **å…³æ³¨ç‚¹** | æ‰€æœ‰æ•°æ®ç‚¹ | æ‰€æœ‰æ•°æ®ç‚¹ | è¾¹ç•Œé™„è¿‘çš„æ”¯æŒå‘é‡ |
        | **ç”Ÿæ´»æ¯”å–»** | ğŸ¯ æ‰”é£é•– | ğŸ” ç¦å°”æ‘©æ–¯ç ´æ¡ˆ | ğŸ›£ï¸ ä¿®æœ€å®½é©¬è·¯ |
        """)
        
        # ç”Ÿæˆæ•°æ®
        with st.sidebar:
            st.markdown("#### æ•°æ®è®¾ç½®")
            n_samples = st.slider("æ ·æœ¬æ•°é‡", 50, 200, 100, 10)
            noise = st.slider("å™ªå£°æ°´å¹³", 0.0, 0.3, 0.1, 0.05)
            random_state = st.slider("éšæœºç§å­", 0, 100, 42, 1)
        
        X, y = InteractiveClassificationOptimization._generate_binary_data(
            n_samples, noise, random_state
        )
        
        # è®­ç»ƒä¸‰ç§æ¨¡å‹
        # 1. æœ€å°äºŒä¹˜æ³• (ç”¨çº¿æ€§å›å½’)
        lr_model = LinearRegression()
        lr_model.fit(X, y)
        
        # 2. æœ€å¤§ä¼¼ç„¶ä¼°è®¡ (é€»è¾‘å›å½’)
        log_model = LogisticRegression()
        log_model.fit(X, y)
        
        # 3. SVM
        svm_model = SVC(kernel='linear', C=1.0)
        svm_model.fit(X, y)
        
        # å¯è§†åŒ–
        fig = make_subplots(
            rows=1, cols=3,
            subplot_titles=(
                "æœ€å°äºŒä¹˜æ³• (MSE)",
                "æœ€å¤§ä¼¼ç„¶ä¼°è®¡ (Cross-Entropy)",
                "SVM (Hinge Loss)"
            )
        )
        
        # åˆ›å»ºç½‘æ ¼ç”¨äºç»˜åˆ¶å†³ç­–è¾¹ç•Œ
        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                             np.linspace(y_min, y_max, 100))
        
        # ç»˜åˆ¶æ¯ä¸ªæ¨¡å‹çš„å†³ç­–è¾¹ç•Œ
        models = [
            (lr_model, 1, "LSE"),
            (log_model, 2, "MLE"),
            (svm_model, 3, "SVM")
        ]
        
        for model, col, name in models:
            # é¢„æµ‹
            if name == "LSE":
                Z = lr_model.predict(np.c_[xx.ravel(), yy.ravel()])
            elif name == "MLE":
                Z = log_model.predict(np.c_[xx.ravel(), yy.ravel()])
            else:  # SVM
                Z = svm_model.predict(np.c_[xx.ravel(), yy.ravel()])
            
            Z = Z.reshape(xx.shape)
            
            # å†³ç­–è¾¹ç•Œ
            fig.add_trace(
                go.Contour(
                    x=xx[0],
                    y=yy[:, 0],
                    z=Z,
                    colorscale=[[0, 'lightblue'], [1, 'lightcoral']],
                    showscale=False,
                    opacity=0.3,
                    contours=dict(start=-1, end=1, size=2),
                    hoverinfo='skip'
                ),
                row=1, col=col
            )
            
            # æ•°æ®ç‚¹
            for label in [-1, 1]:
                mask = y == label
                fig.add_trace(
                    go.Scatter(
                        x=X[mask, 0],
                        y=X[mask, 1],
                        mode='markers',
                        name=f'Class {label}' if col == 1 else None,
                        marker=dict(
                            size=8,
                            color='blue' if label == -1 else 'red',
                            line=dict(width=1, color='white')
                        ),
                        showlegend=(col == 1)
                    ),
                    row=1, col=col
                )
            
            # æ·»åŠ å†³ç­–è¾¹ç•Œçº¿
            if name == "SVM":
                # å¯¹äºSVMï¼Œçªå‡ºæ˜¾ç¤ºæ”¯æŒå‘é‡
                sv_mask = np.zeros(len(X), dtype=bool)
                sv_mask[svm_model.support_] = True
                fig.add_trace(
                    go.Scatter(
                        x=X[sv_mask, 0],
                        y=X[sv_mask, 1],
                        mode='markers',
                        name='Support Vectors' if col == 3 else None,
                        marker=dict(
                            size=12,
                            color='yellow',
                            symbol='circle-open',
                            line=dict(width=3, color='black')
                        ),
                        showlegend=(col == 3)
                    ),
                    row=1, col=col
                )
        
        fig.update_xaxes(title_text="Feature 1")
        fig.update_yaxes(title_text="Feature 2")
        fig.update_layout(height=500, showlegend=True)
        
        st.plotly_chart(fig, use_container_width=True)
        
        # æ€§èƒ½å¯¹æ¯”
        st.markdown("### ğŸ“Š æ€§èƒ½å¯¹æ¯”")
        
        # è®¡ç®—å‡†ç¡®ç‡
        lr_acc = np.mean((lr_model.predict(X) > 0) == (y > 0))
        log_acc = log_model.score(X, y)
        svm_acc = svm_model.score(X, y)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æœ€å°äºŒä¹˜æ³•", f"{lr_acc:.1%}")
        with col2:
            st.metric("æœ€å¤§ä¼¼ç„¶ä¼°è®¡", f"{log_acc:.1%}")
        with col3:
            st.metric("SVM", f"{svm_acc:.1%}")
        
        st.success(r"""
        **å…³é”®è§‚å¯Ÿ**:
        
        1. **å†³ç­–è¾¹ç•Œå·®å¼‚**:
           - LSE: ç›´çº¿ï¼Œä½†å¯èƒ½å—ç¦»ç¾¤ç‚¹å½±å“å¤§
           - MLE: å¹³æ»‘çš„æ¦‚ç‡è¾¹ç•Œ
           - SVM: æœ€å¤§åŒ–é—´éš”çš„è¾¹ç•Œï¼Œåªå…³å¿ƒæ”¯æŒå‘é‡
        
        2. **é²æ£’æ€§**:
           - LSEå¯¹ç¦»ç¾¤ç‚¹æ•æ„Ÿ
           - MLEç›¸å¯¹å¹³è¡¡
           - SVMæœ€é²æ£’ï¼ˆå¿½ç•¥è¿œç¦»è¾¹ç•Œçš„ç‚¹ï¼‰
        
        3. **é€‚ç”¨åœºæ™¯**:
           - LSE: ç®€å•å¿«é€Ÿï¼Œä½†ä¸æ¨èç”¨äºåˆ†ç±»
           - MLE: ç°ä»£æ·±åº¦å­¦ä¹ çš„æ ‡å‡†é€‰æ‹©
           - SVM: å°æ ·æœ¬ã€é«˜ç»´æ•°æ®çš„ç»å…¸æ–¹æ³•
        """)

    
    @staticmethod
    def _render_least_squares():
        """æœ€å°äºŒä¹˜æ³•æ¼”ç¤º"""
        st.markdown("### ğŸ¯ æœ€å°äºŒä¹˜æ³•ï¼šæ‰”é£é•–æ¸¸æˆ")
        
        st.markdown(r"""
        **æ ¸å¿ƒæ€æƒ³**: æŠŠæ¨¡å‹è¾“å‡ºçœ‹ä½œè¿ç»­æ•°å€¼ï¼Œç›´æ¥æ‹ŸåˆçœŸå®æ ‡ç­¾
        
        **æŸå¤±å‡½æ•°**:
        """)
        
        st.latex(r"""
        \mathcal{L}_{MSE} = \frac{1}{n} \sum_{i=1}^n (f(x_i) - y_i)^2
        """)
        
        st.markdown(r"""
        **ç”Ÿæ´»æ¯”å–»**: ğŸ¯ æ‰”é£é•–
        - çœŸå®æ ‡ç­¾æ˜¯é¶å¿ƒ
        - æ¨¡å‹è¾“å‡ºæ˜¯é£é•–è½ç‚¹
        - è®¡ç®—æ¯ä¸ªé£é•–ç¦»é¶å¿ƒçš„**å¹³æ–¹è·ç¦»**
        - ç›®æ ‡ï¼šè®©æ€»å¹³æ–¹è·ç¦»æœ€å°
        """)
        
        # ç”Ÿæˆæ•°æ®
        with st.sidebar:
            st.markdown("#### å‚æ•°è®¾ç½®")
            n_samples = st.slider("æ ·æœ¬æ•°é‡", 50, 200, 100, 10)
            show_outlier = st.checkbox("æ·»åŠ ç¦»ç¾¤ç‚¹", value=False)
            show_confident = st.checkbox("å±•ç¤º'å¤ªå¥½'é¢„æµ‹çš„æƒ©ç½š", value=False)
        
        X, y = InteractiveClassificationOptimization._generate_binary_data(n_samples)
        
        # æ·»åŠ ç¦»ç¾¤ç‚¹
        if show_outlier:
            outlier_x = np.array([[X[:, 0].max() - 0.5, X[:, 1].max() - 0.5]])
            outlier_y = np.array([-1])  # ä¸å‘¨å›´ç‚¹ç›¸å
            X = np.vstack([X, outlier_x])
            y = np.hstack([y, outlier_y])
        
        # è®­ç»ƒæ¨¡å‹
        lr_model = LinearRegression()
        lr_model.fit(X, y)
        
        # é¢„æµ‹
        y_pred = lr_model.predict(X)
        
        # å¯è§†åŒ–
        fig = make_subplots(
            rows=1, cols=2,
            subplot_titles=(
                "å†³ç­–è¾¹ç•Œä¸æ•°æ®ç‚¹",
                "å¹³æ–¹è¯¯å·®åˆ†å¸ƒ"
            )
        )
        
        # å·¦å›¾ï¼šå†³ç­–è¾¹ç•Œ
        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                             np.linspace(y_min, y_max, 100))
        Z = lr_model.predict(np.c_[xx.ravel(), yy.ravel()])
        Z = Z.reshape(xx.shape)
        
        fig.add_trace(
            go.Contour(
                x=xx[0],
                y=yy[:, 0],
                z=Z,
                colorscale='RdBu',
                showscale=True,
                opacity=0.5,
                colorbar=dict(x=0.45)
            ),
            row=1, col=1
        )
        
        # æ•°æ®ç‚¹
        for label in [-1, 1]:
            mask = y == label
            fig.add_trace(
                go.Scatter(
                    x=X[mask, 0],
                    y=X[mask, 1],
                    mode='markers',
                    name=f'y={label}',
                    marker=dict(
                        size=10,
                        color='blue' if label == -1 else 'red',
                        line=dict(width=1, color='white')
                    )
                ),
                row=1, col=1
            )
        
        # å¦‚æœæœ‰ç¦»ç¾¤ç‚¹ï¼Œç‰¹åˆ«æ ‡æ³¨
        if show_outlier:
            fig.add_trace(
                go.Scatter(
                    x=[X[-1, 0]],
                    y=[X[-1, 1]],
                    mode='markers',
                    name='ç¦»ç¾¤ç‚¹',
                    marker=dict(
                        size=15,
                        color='yellow',
                        symbol='star',
                        line=dict(width=2, color='black')
                    )
                ),
                row=1, col=1
            )
        
        # å³å›¾ï¼šå¹³æ–¹è¯¯å·®
        squared_errors = (y_pred - y) ** 2
        colors = ['lightgreen' if e < 1 else 'orange' if e < 4 else 'red' 
                  for e in squared_errors]
        
        fig.add_trace(
            go.Bar(
                y=squared_errors,
                marker=dict(color=colors),
                showlegend=False,
                text=[f'{e:.2f}' for e in squared_errors],
                textposition='outside'
            ),
            row=1, col=2
        )
        
        fig.update_xaxes(title_text="Feature 1", row=1, col=1)
        fig.update_yaxes(title_text="Feature 2", row=1, col=1)
        fig.update_xaxes(title_text="æ ·æœ¬ç´¢å¼•", row=1, col=2)
        fig.update_yaxes(title_text="å¹³æ–¹è¯¯å·®", row=1, col=2)
        fig.update_layout(height=500, showlegend=True)
        
        st.plotly_chart(fig, use_container_width=True)
        
        # åˆ†æ
        st.markdown("### ğŸ“Š è¯¯å·®åˆ†æ")
        
        mse = np.mean(squared_errors)
        max_error_idx = np.argmax(squared_errors)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("å¹³å‡å¹³æ–¹è¯¯å·®", f"{mse:.3f}")
        with col2:
            st.metric("æœ€å¤§è¯¯å·®", f"{squared_errors[max_error_idx]:.3f}")
        with col3:
            st.metric("å‡†ç¡®ç‡", f"{np.mean((y_pred > 0) == (y > 0)):.1%}")
        
        # å±•ç¤º"å¤ªå¥½"é¢„æµ‹çš„é—®é¢˜
        if show_confident:
            st.warning(r"""
            **é—®é¢˜ï¼šæƒ©ç½š"å¤ªå¥½"çš„é¢„æµ‹**
            
            å‡è®¾çœŸå®æ ‡ç­¾ $y = 1$ï¼š
            - é¢„æµ‹ $f(x) = 1.1$: è¯¯å·® = $(1.1 - 1)^2 = 0.01$ âœ… å¾ˆå¥½
            - é¢„æµ‹ $f(x) = 5.0$: è¯¯å·® = $(5.0 - 1)^2 = 16.0$ âŒ éå¸¸å·®ï¼
            
            ä½†åœ¨åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œ$f(x) = 5.0$ è¡¨ç¤ºæ¨¡å‹**éå¸¸ç¡®ä¿¡**è¿™æ˜¯æ­£ç±»ï¼Œ
            è¿™åº”è¯¥è¢«å¥–åŠ±ï¼Œè€Œä¸æ˜¯æƒ©ç½šï¼
            
            è¿™å°±æ˜¯ä¸ºä»€ä¹ˆ**MSEä¸é€‚åˆåˆ†ç±»**çš„æ ¹æœ¬åŸå› ã€‚
            """)
        
        st.info(r"""
        **æœ€å°äºŒä¹˜æ³•çš„ä¸‰å¤§é—®é¢˜**:
        
        1. **é€»è¾‘å°´å°¬** ğŸ’­
           - æŠŠ $\{-1, +1\}$ è¿™æ ·çš„ç±»åˆ«æ ‡ç­¾å½“ä½œè¿ç»­æ•°å€¼æ‹Ÿåˆ
           - è¾“å‡ºå¯èƒ½æ˜¯ $-5$ æˆ– $10$ï¼Œä½†æ ‡ç­¾åªèƒ½æ˜¯ $-1$ æˆ– $1$
        
        2. **ç¦»ç¾¤ç‚¹æ•æ„Ÿ** ğŸ¯
           - ä¸€ä¸ªç¦»ç¾¤ç‚¹äº§ç”Ÿå·¨å¤§çš„å¹³æ–¹è¯¯å·®
           - å¯èƒ½æŠŠæ•´ä¸ªæ¨¡å‹"å¸¦å"
           - è¯•è¯•æ·»åŠ ç¦»ç¾¤ç‚¹çœ‹æ•ˆæœï¼
        
        3. **æƒ©ç½š"å¤ªå¥½"çš„é¢„æµ‹** âš ï¸
           - æ¨¡å‹å¾ˆæœ‰ä¿¡å¿ƒçš„æ­£ç¡®é¢„æµ‹åè€Œè¢«é‡ç½š
           - è¿èƒŒåˆ†ç±»ä»»åŠ¡çš„ç›´è§‰
        
        **ç»“è®º**: MSEé€‚åˆå›å½’ï¼Œä¸é€‚åˆåˆ†ç±»ï¼
        """)

    
    @staticmethod
    def _render_mle():
        """æœ€å¤§ä¼¼ç„¶ä¼°è®¡æ¼”ç¤º"""
        st.markdown("### ğŸ” æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼šç¦å°”æ‘©æ–¯ç ´æ¡ˆ")
        
        st.markdown(r"""
        **æ ¸å¿ƒæ€æƒ³**: æŠŠæ¨¡å‹è¾“å‡ºè½¬æ¢ä¸ºæ¦‚ç‡ï¼Œæœ€å¤§åŒ–è§‚æµ‹æ•°æ®çš„ä¼¼ç„¶
        
        **ä»è¾“å‡ºåˆ°æ¦‚ç‡**:
        """)
        
        st.latex(r"""
        p(y=1|x) = \sigma(f(x)) = \frac{1}{1 + e^{-f(x)}}
        """)
        
        st.markdown(r"""
        **æŸå¤±å‡½æ•° (äº¤å‰ç†µ)**:
        """)
        
        st.latex(r"""
        \mathcal{L}_{CE} = -\sum_{i=1}^n [y_i \log p_i + (1-y_i) \log(1-p_i)]
        """)
        
        st.markdown(r"""
        **ç”Ÿæ´»æ¯”å–»**: ğŸ” ç¦å°”æ‘©æ–¯ç ´æ¡ˆ
        - è®­ç»ƒæ•°æ®æ˜¯ä¸€ä¸²è„šå°ï¼ˆçº¿ç´¢ï¼‰
        - æ¨¡å‹å‚æ•° $\theta$ æ˜¯ä¸åŒçš„å«Œç–‘äºº
        - **ç›®æ ‡**: æ‰¾é‚£ä¸ªæœ€æœ‰å¯èƒ½ç•™ä¸‹è¿™ä¸²è„šå°çš„å«Œç–‘äºº
        """)
        
        # Sigmoidå‡½æ•°æ¼”ç¤º
        with st.sidebar:
            st.markdown("#### å‚æ•°è®¾ç½®")
            show_sigmoid = st.checkbox("æ˜¾ç¤ºSigmoidè½¬æ¢", value=True)
            n_samples = st.slider("æ ·æœ¬æ•°é‡", 50, 200, 100, 10)
        
        X, y = InteractiveClassificationOptimization._generate_binary_data(n_samples)
        
        # è½¬æ¢yåˆ°{0, 1}ç”¨äºé€»è¾‘å›å½’
        y_binary = (y + 1) // 2
        
        # è®­ç»ƒæ¨¡å‹
        log_model = LogisticRegression()
        log_model.fit(X, y_binary)
        
        # é¢„æµ‹æ¦‚ç‡
        y_proba = log_model.predict_proba(X)[:, 1]
        
        # å¯è§†åŒ–
        if show_sigmoid:
            # æ˜¾ç¤ºSigmoidå‡½æ•°
            fig = make_subplots(
                rows=1, cols=2,
                subplot_titles=(
                    "Sigmoidå‡½æ•°ï¼šä»è¾“å‡ºåˆ°æ¦‚ç‡",
                    "æ¦‚ç‡åˆ†å¸ƒ"
                )
            )
            
            # å·¦å›¾ï¼šSigmoidå‡½æ•°
            z = np.linspace(-6, 6, 100)
            sigmoid = 1 / (1 + np.exp(-z))
            
            fig.add_trace(
                go.Scatter(
                    x=z,
                    y=sigmoid,
                    mode='lines',
                    name='Ïƒ(z)',
                    line=dict(color='purple', width=3)
                ),
                row=1, col=1
            )
            
            # æ ‡æ³¨å…³é”®ç‚¹
            key_points = [(-2, 1/(1+np.exp(2))), (0, 0.5), (2, 1/(1+np.exp(-2)))]
            for z_val, sig_val in key_points:
                fig.add_trace(
                    go.Scatter(
                        x=[z_val],
                        y=[sig_val],
                        mode='markers+text',
                        marker=dict(size=10, color='red'),
                        text=[f'({z_val:.0f}, {sig_val:.2f})'],
                        textposition='top center',
                        showlegend=False
                    ),
                    row=1, col=1
                )
            
            fig.add_hline(y=0.5, line_dash="dash", line_color="gray", row=1, col=1)
            fig.add_vline(x=0, line_dash="dash", line_color="gray", row=1, col=1)
            
            # å³å›¾ï¼šæ¦‚ç‡åˆ†å¸ƒ
            fig.add_trace(
                go.Histogram(
                    x=y_proba[y_binary == 0],
                    name='y=0 (è´Ÿç±»)',
                    marker_color='blue',
                    opacity=0.6,
                    nbinsx=20
                ),
                row=1, col=2
            )
            
            fig.add_trace(
                go.Histogram(
                    x=y_proba[y_binary == 1],
                    name='y=1 (æ­£ç±»)',
                    marker_color='red',
                    opacity=0.6,
                    nbinsx=20
                ),
                row=1, col=2
            )
            
            fig.add_vline(x=0.5, line_dash="dash", line_color="green", 
                         annotation_text="å†³ç­–é˜ˆå€¼", row=1, col=2)
            
            fig.update_xaxes(title_text="f(x) (æ¨¡å‹è¾“å‡º)", row=1, col=1)
            fig.update_yaxes(title_text="Ïƒ(f(x)) (æ¦‚ç‡)", row=1, col=1)
            fig.update_xaxes(title_text="é¢„æµ‹æ¦‚ç‡", row=1, col=2)
            fig.update_yaxes(title_text="æ ·æœ¬æ•°é‡", row=1, col=2)
            fig.update_layout(height=500, showlegend=True, barmode='overlay')
            
            st.plotly_chart(fig, use_container_width=True)
        
        # å†³ç­–è¾¹ç•Œå’Œç½®ä¿¡åº¦
        st.markdown("### ğŸ¨ å†³ç­–è¾¹ç•Œä¸ç½®ä¿¡åº¦")
        
        fig2 = go.Figure()
        
        # åˆ›å»ºç½‘æ ¼
        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                             np.linspace(y_min, y_max, 100))
        
        # é¢„æµ‹æ¦‚ç‡
        Z = log_model.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]
        Z = Z.reshape(xx.shape)
        
        # ç»˜åˆ¶æ¦‚ç‡çƒ­å›¾
        fig2.add_trace(
            go.Contour(
                x=xx[0],
                y=yy[:, 0],
                z=Z,
                colorscale='RdBu_r',
                showscale=True,
                colorbar=dict(title="P(y=1)"),
                contours=dict(
                    start=0,
                    end=1,
                    size=0.1
                )
            )
        )
        
        # æ•°æ®ç‚¹ï¼Œå¤§å°è¡¨ç¤ºç½®ä¿¡åº¦
        for label in [0, 1]:
            mask = y_binary == label
            confidences = y_proba[mask] if label == 1 else (1 - y_proba[mask])
            
            fig2.add_trace(
                go.Scatter(
                    x=X[mask, 0],
                    y=X[mask, 1],
                    mode='markers',
                    name=f'y={label}',
                    marker=dict(
                        size=10 + 20 * confidences,  # å¤§å°è¡¨ç¤ºç½®ä¿¡åº¦
                        color='white' if label == 0 else 'red',
                        line=dict(width=2, color='black')
                    ),
                    text=[f'P={p:.2f}' for p in (y_proba[mask] if label == 1 else 1-y_proba[mask])],
                    hovertemplate='%{text}<extra></extra>'
                )
            )
        
        fig2.update_layout(
            title="å†³ç­–è¾¹ç•Œä¸é¢„æµ‹ç½®ä¿¡åº¦ï¼ˆåœ†åœˆå¤§å°è¡¨ç¤ºç½®ä¿¡åº¦ï¼‰",
            xaxis_title="Feature 1",
            yaxis_title="Feature 2",
            height=500
        )
        
        st.plotly_chart(fig2, use_container_width=True)
        
        # æ€§èƒ½æŒ‡æ ‡
        st.markdown("### ğŸ“Š æ¨¡å‹æ€§èƒ½")
        
        y_pred = (y_proba > 0.5).astype(int)
        accuracy = np.mean(y_pred == y_binary)
        avg_confidence = np.mean(np.maximum(y_proba, 1 - y_proba))
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("å‡†ç¡®ç‡", f"{accuracy:.1%}")
        with col2:
            st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_confidence:.1%}")
        with col3:
            # è®¡ç®—äº¤å‰ç†µ
            epsilon = 1e-15
            ce = -np.mean(y_binary * np.log(y_proba + epsilon) + 
                         (1 - y_binary) * np.log(1 - y_proba + epsilon))
            st.metric("äº¤å‰ç†µ", f"{ce:.3f}")
        
        st.success(r"""
        **æœ€å¤§ä¼¼ç„¶ä¼°è®¡çš„ä¼˜åŠ¿**:
        
        1. **æ¦‚ç‡è§£é‡Š** ğŸ²
           - è¾“å‡ºä¸æ˜¯ç¡¬åˆ†ç±»ï¼Œè€Œæ˜¯æ¦‚ç‡
           - å‘Šè¯‰æˆ‘ä»¬æ¨¡å‹çš„"ç¡®ä¿¡ç¨‹åº¦"
           - å¯ä»¥è®¾ç½®ä¸åŒçš„å†³ç­–é˜ˆå€¼
        
        2. **åˆç†çš„æŸå¤±å‡½æ•°** âœ…
           - å¥–åŠ±æ­£ç¡®ä¸”æœ‰ä¿¡å¿ƒçš„é¢„æµ‹
           - ä¸æƒ©ç½š"å¤ªå¥½"çš„é¢„æµ‹
           - å¯¹æ‰€æœ‰ç‚¹éƒ½æœ‰æ¢¯åº¦ä¿¡å·
        
        3. **ç°ä»£æ ‡å‡†** ğŸŒŸ
           - ç¥ç»ç½‘ç»œåˆ†ç±»çš„æ ‡å‡†æŸå¤±å‡½æ•°
           - Softmax + Cross-Entropy
           - ä»Logistic Regressionåˆ°æ·±åº¦å­¦ä¹ 
        
        **ä¸ºä»€ä¹ˆäº¤å‰ç†µæ›´å¥½ï¼Ÿ**
        - åˆ†ç±»æ­£ç¡®ä¸”æ¦‚ç‡â†’1æ—¶ï¼Œlossâ†’0
        - åˆ†ç±»é”™è¯¯ä¸”æ¦‚ç‡â†’0æ—¶ï¼Œlossâ†’âˆ
        - æä¾›æŒç»­çš„ä¼˜åŒ–åŠ¨åŠ›
        """)

    
    @staticmethod
    def _render_svm():
        """SVMé—´éš”æœ€å¤§åŒ–æ¼”ç¤º"""
        st.markdown("### ğŸ›£ï¸ SVMï¼šä¿®æœ€å®½çš„é©¬è·¯")
        
        st.markdown(r"""
        **æ ¸å¿ƒæ€æƒ³**: åœ¨ç±»åˆ«ä¹‹é—´ä¿®ä¸€æ¡æœ€å®½çš„"åŒé»„çº¿"ï¼ˆæœ€å¤§åŒ–é—´éš”ï¼‰
        
        **ä¼˜åŒ–ç›®æ ‡**:
        """)
        
        st.latex(r"""
        \begin{cases}
        \min \frac{1}{2} \|w\|^2  & \text{(è®©é©¬è·¯å°½å¯èƒ½å®½)} \\
        \text{s.t. } y_i(w^T x_i + b) \ge 1 & \text{(æ‰€æœ‰äººéƒ½åœ¨è·¯ä¸¤è¾¹)}
        \end{cases}
        """)
        
        st.markdown(r"""
        **Hinge Loss**:
        """)
        
        st.latex(r"""
        \mathcal{L}_{Hinge}(y, f(x)) = \max(0, 1 - y \cdot f(x))
        """)
        
        st.markdown(r"""
        **ç”Ÿæ´»æ¯”å–»**: ğŸ›£ï¸ ä¿®é©¬è·¯
        - è¦æŠŠä¸¤ç±»äººå®Œå…¨éš”å¼€
        - åœ¨ä¸­é—´ä¿®ä¸€æ¡æœ€å®½çš„åŒé»„çº¿
        - æ­»æ­»é¡¶åœ¨è·¯è¾¹ç¼˜çš„äººæ˜¯"æ”¯æŒå‘é‡"
        """)
        
        # ç”Ÿæˆæ•°æ®
        with st.sidebar:
            st.markdown("#### å‚æ•°è®¾ç½®")
            C = st.slider("C (è½¯é—´éš”æƒ©ç½š)", 0.1, 10.0, 1.0, 0.1)
            n_samples = st.slider("æ ·æœ¬æ•°é‡", 50, 200, 100, 10)
            show_margin = st.checkbox("æ˜¾ç¤ºé—´éš”å¸¦", value=True)
        
        X, y = InteractiveClassificationOptimization._generate_binary_data(n_samples)
        
        # è®­ç»ƒSVM
        svm_model = SVC(kernel='linear', C=C)
        svm_model.fit(X, y)
        
        # è·å–å‚æ•°
        w = svm_model.coef_[0]
        b = svm_model.intercept_[0]
        
        # æ”¯æŒå‘é‡
        support_vectors = X[svm_model.support_]
        
        # å¯è§†åŒ–
        fig = go.Figure()
        
        # åˆ›å»ºç½‘æ ¼
        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                             np.linspace(y_min, y_max, 100))
        
        # é¢„æµ‹
        Z = svm_model.decision_function(np.c_[xx.ravel(), yy.ravel()])
        Z = Z.reshape(xx.shape)
        
        # ç»˜åˆ¶å†³ç­–è¾¹ç•Œå’Œé—´éš”
        fig.add_trace(
            go.Contour(
                x=xx[0],
                y=yy[:, 0],
                z=Z,
                colorscale='RdBu',
                showscale=True,
                colorbar=dict(title="Decision Function"),
                contours=dict(
                    start=-3,
                    end=3,
                    size=0.5
                )
            )
        )
        
        # å†³ç­–è¾¹ç•Œ (f(x) = 0)
        fig.add_trace(
            go.Contour(
                x=xx[0],
                y=yy[:, 0],
                z=Z,
                showscale=False,
                contours=dict(
                    start=0,
                    end=0,
                    coloring='lines'
                ),
                line=dict(color='black', width=3),
                name='å†³ç­–è¾¹ç•Œ'
            )
        )
        
        # é—´éš”è¾¹ç•Œ
        if show_margin:
            for margin_val, color, name in [(1, 'green', 'æ­£é—´éš”'), (-1, 'blue', 'è´Ÿé—´éš”')]:
                fig.add_trace(
                    go.Contour(
                        x=xx[0],
                        y=yy[:, 0],
                        z=Z,
                        showscale=False,
                        contours=dict(
                            start=margin_val,
                            end=margin_val,
                            coloring='lines'
                        ),
                        line=dict(color=color, width=2, dash='dash'),
                        name=name
                    )
                )
        
        # æ•°æ®ç‚¹
        for label in [-1, 1]:
            mask = y == label
            fig.add_trace(
                go.Scatter(
                    x=X[mask, 0],
                    y=X[mask, 1],
                    mode='markers',
                    name=f'Class {label}',
                    marker=dict(
                        size=8,
                        color='blue' if label == -1 else 'red',
                        line=dict(width=1, color='white')
                    )
                )
            )
        
        # æ”¯æŒå‘é‡
        fig.add_trace(
            go.Scatter(
                x=support_vectors[:, 0],
                y=support_vectors[:, 1],
                mode='markers',
                name='æ”¯æŒå‘é‡',
                marker=dict(
                    size=15,
                    color='yellow',
                    symbol='circle-open',
                    line=dict(width=3, color='black')
                )
            )
        )
        
        # è®¡ç®—é—´éš”å®½åº¦
        margin_width = 2 / np.linalg.norm(w)
        
        fig.update_layout(
            title=f"SVMå†³ç­–è¾¹ç•Œä¸é—´éš” (C={C}, é—´éš”å®½åº¦={margin_width:.3f})",
            xaxis_title="Feature 1",
            yaxis_title="Feature 2",
            height=600,
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # åˆ†æ
        st.markdown("### ğŸ“Š SVMåˆ†æ")
        
        n_support = len(svm_model.support_)
        accuracy = svm_model.score(X, y)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ”¯æŒå‘é‡æ•°é‡", f"{n_support}")
        with col2:
            st.metric("é—´éš”å®½åº¦", f"{margin_width:.3f}")
        with col3:
            st.metric("å‡†ç¡®ç‡", f"{accuracy:.1%}")
        
        # Hinge Lossæ¼”ç¤º
        st.markdown("### ğŸ“‰ Hinge Lossçš„ç‰¹æ€§")
        
        # è®¡ç®—æ¯ä¸ªç‚¹çš„Hinge Loss
        decision_values = svm_model.decision_function(X)
        hinge_losses = np.maximum(0, 1 - y * decision_values)
        
        fig2 = make_subplots(
            rows=1, cols=2,
            subplot_titles=(
                "Hinge Loss vs æ ·æœ¬",
                "Hinge Losså‡½æ•°"
            )
        )
        
        # å·¦å›¾ï¼šæ¯ä¸ªæ ·æœ¬çš„loss
        colors = ['green' if loss == 0 else 'orange' if loss < 1 else 'red' 
                  for loss in hinge_losses]
        
        fig2.add_trace(
            go.Bar(
                y=hinge_losses,
                marker=dict(color=colors),
                showlegend=False,
                text=[f'{loss:.2f}' for loss in hinge_losses],
                textposition='outside'
            ),
            row=1, col=1
        )
        
        # å³å›¾ï¼šHinge Losså‡½æ•°
        margin = np.linspace(-2, 3, 100)
        hinge = np.maximum(0, 1 - margin)
        
        fig2.add_trace(
            go.Scatter(
                x=margin,
                y=hinge,
                mode='lines',
                name='Hinge Loss',
                line=dict(color='purple', width=3)
            ),
            row=1, col=2
        )
        
        # æ ‡æ³¨å…³é”®åŒºåŸŸ
        fig2.add_vrect(x0=-2, x1=1, fillcolor="red", opacity=0.1, 
                      annotation_text="Loss > 0", row=1, col=2)
        fig2.add_vrect(x0=1, x1=3, fillcolor="green", opacity=0.1,
                      annotation_text="Loss = 0", row=1, col=2)
        fig2.add_vline(x=1, line_dash="dash", line_color="black", row=1, col=2)
        
        fig2.update_xaxes(title_text="æ ·æœ¬ç´¢å¼•", row=1, col=1)
        fig2.update_yaxes(title_text="Hinge Loss", row=1, col=1)
        fig2.update_xaxes(title_text="yÂ·f(x) (å‡½æ•°é—´éš”)", row=1, col=2)
        fig2.update_yaxes(title_text="Loss", row=1, col=2)
        fig2.update_layout(height=400)
        
        st.plotly_chart(fig2, use_container_width=True)
        
        st.success(r"""
        **SVMçš„ç‹¬ç‰¹ä¹‹å¤„**:
        
        1. **åªå…³å¿ƒè¾¹ç•Œ** ğŸ¯
           - åªæœ‰æ”¯æŒå‘é‡ï¼ˆé»„è‰²åœˆï¼‰å½±å“å†³ç­–è¾¹ç•Œ
           - è¿œç¦»è¾¹ç•Œçš„ç‚¹Loss=0ï¼Œä¸å‚ä¸ä¼˜åŒ–
           - è¿™ä½¿å¾—SVMå¯¹è¿œç¦»è¾¹ç•Œçš„å™ªå£°ä¸æ•æ„Ÿ
        
        2. **æœ€å¤§åŒ–é—´éš”** ğŸ“
           - é—´éš”å®½åº¦ = $\frac{2}{\|w\|}$
           - æœ€å°åŒ– $\|w\|^2$ âŸº æœ€å¤§åŒ–é—´éš”
           - å¤§é—´éš” â†’ æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼ˆä½VCç»´ï¼‰
        
        3. **Hinge Lossçš„æ™ºæ…§** ğŸ’¡
           - å½“ $y \cdot f(x) \ge 1$: Loss = 0ï¼ˆå·²ç»å¾ˆå¥½äº†ï¼Œä¸ç®¡å®ƒï¼‰
           - å½“ $y \cdot f(x) < 1$: Loss = $1 - y \cdot f(x)$ï¼ˆéœ€è¦æ”¹è¿›ï¼‰
           - æ—¢ä¸æƒ©ç½š"å¤ªå¥½"ï¼Œä¹Ÿä¸è¿‡åº¦å…³æ³¨"å·²ç»å¤Ÿå¥½"çš„ç‚¹
        
        4. **Cå‚æ•°çš„ä½œç”¨** âš–ï¸
           - Cå°ï¼šå…è®¸æ›´å¤šè¯¯åˆ†ç±»ï¼Œè¿½æ±‚æ›´å¤§é—´éš”ï¼ˆè½¯é—´éš”ï¼‰
           - Cå¤§ï¼šå‡å°‘è¯¯åˆ†ç±»ï¼Œå¯èƒ½é—´éš”å˜å°
           - è°ƒæ•´Cè§‚å¯Ÿæ”¯æŒå‘é‡å’Œé—´éš”çš„å˜åŒ–ï¼
        """)

    
    @staticmethod
    def _render_loss_comparison():
        """æŸå¤±å‡½æ•°å¯¹æ¯”"""
        st.markdown("### ğŸ“‰ ä¸‰ç§æŸå¤±å‡½æ•°çš„å¯¹æ¯”")
        
        st.markdown(r"""
        **æ ¸å¿ƒé—®é¢˜**: å¯¹äºç›¸åŒçš„é¢„æµ‹è¯¯å·®ï¼Œä¸‰ç§æŸå¤±å‡½æ•°å¦‚ä½•ååº”ï¼Ÿ
        
        è®¾å®šï¼šçœŸå®æ ‡ç­¾ $y = 1$ï¼Œé¢„æµ‹å€¼ $f(x)$ ä» -3 åˆ° 3
        """)
        
        # ç”Ÿæˆæ•°æ®
        f_x = np.linspace(-3, 3, 200)
        y = 1  # å‡è®¾çœŸå®æ ‡ç­¾ä¸º1
        
        # ä¸‰ç§æŸå¤±å‡½æ•°
        # 1. MSE
        mse_loss = (f_x - y) ** 2
        
        # 2. Cross-Entropy (é€šè¿‡sigmoidè½¬æ¢)
        sigmoid = 1 / (1 + np.exp(-f_x))
        ce_loss = -np.log(sigmoid + 1e-15)
        
        # 3. Hinge Loss
        hinge_loss = np.maximum(0, 1 - y * f_x)
        
        # å¯è§†åŒ–
        fig = go.Figure()
        
        fig.add_trace(
            go.Scatter(
                x=f_x,
                y=mse_loss,
                mode='lines',
                name='MSE',
                line=dict(color='blue', width=3)
            )
        )
        
        fig.add_trace(
            go.Scatter(
                x=f_x,
                y=ce_loss,
                mode='lines',
                name='Cross-Entropy',
                line=dict(color='red', width=3)
            )
        )
        
        fig.add_trace(
            go.Scatter(
                x=f_x,
                y=hinge_loss,
                mode='lines',
                name='Hinge Loss',
                line=dict(color='green', width=3)
            )
        )
        
        # æ ‡æ³¨å…³é”®åŒºåŸŸ
        fig.add_vline(x=0, line_dash="dash", line_color="gray", 
                     annotation_text="å†³ç­–è¾¹ç•Œ")
        fig.add_vline(x=1, line_dash="dash", line_color="orange",
                     annotation_text="SVMé—´éš”")
        
        # æ ‡æ³¨åŒºåŸŸ
        fig.add_vrect(x0=-3, x1=0, fillcolor="red", opacity=0.1,
                     annotation_text="åˆ†ç±»é”™è¯¯", annotation_position="top left")
        fig.add_vrect(x0=0, x1=1, fillcolor="yellow", opacity=0.1,
                     annotation_text="æ­£ç¡®ä½†ä¸å¤Ÿè‡ªä¿¡", annotation_position="top left")
        fig.add_vrect(x0=1, x1=3, fillcolor="green", opacity=0.1,
                     annotation_text="æ­£ç¡®ä¸”è‡ªä¿¡", annotation_position="top left")
        
        fig.update_layout(
            title="ä¸‰ç§æŸå¤±å‡½æ•°å¯¹æ¯” (y=1)",
            xaxis_title="f(x) (æ¨¡å‹è¾“å‡º)",
            yaxis_title="Loss",
            yaxis_range=[0, 10],
            height=500,
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # è¯¦ç»†åˆ†æ
        st.markdown("### ğŸ” å…³é”®è§‚å¯Ÿ")
        
        # åˆ›å»ºå¯¹æ¯”è¡¨
        import pandas as pd
        
        scenarios = [
            {"f(x)": -2, "æƒ…å†µ": "ä¸¥é‡é”™è¯¯"},
            {"f(x)": -0.5, "æƒ…å†µ": "è½»å¾®é”™è¯¯"},
            {"f(x)": 0.5, "æƒ…å†µ": "æ­£ç¡®ä½†ä¸è‡ªä¿¡"},
            {"f(x)": 1.5, "æƒ…å†µ": "æ­£ç¡®ä¸”è‡ªä¿¡"},
            {"f(x)": 3.0, "æƒ…å†µ": "éå¸¸è‡ªä¿¡"}
        ]
        
        for scenario in scenarios:
            fx = scenario["f(x)"]
            scenario["MSE"] = f"{(fx - y)**2:.2f}"
            scenario["Cross-Entropy"] = f"{-np.log(1/(1+np.exp(-fx)) + 1e-15):.2f}"
            scenario["Hinge"] = f"{max(0, 1 - fx):.2f}"
        
        df = pd.DataFrame(scenarios)
        st.dataframe(df, use_container_width=True)
        
        # ä¸‰åˆ—å¯¹æ¯”
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("#### ğŸ¯ MSE")
            st.warning("""
            **é—®é¢˜**:
            - âŒ æƒ©ç½š"å¤ªè‡ªä¿¡"çš„æ­£ç¡®é¢„æµ‹
            - f(x)=3æ—¶ï¼ŒLoss=4ï¼ˆå¾ˆå¤§ï¼ï¼‰
            - ä¸ç¬¦åˆåˆ†ç±»ä»»åŠ¡çš„ç›´è§‰
            - æ¢¯åº¦åœ¨è¿œå¤„å¾ˆå¤§ï¼Œå¯èƒ½ä¸ç¨³å®š
            """)
        
        with col2:
            st.markdown("#### ğŸ” Cross-Entropy")
            st.success("""
            **ä¼˜åŠ¿**:
            - âœ… æ­£ç¡®ä¸”è‡ªä¿¡æ—¶Lossâ†’0
            - âœ… é”™è¯¯æ—¶Lossâ†’âˆ
            - âœ… å¤„å¤„æœ‰æ¢¯åº¦
            - âœ… ç°ä»£æ·±åº¦å­¦ä¹ æ ‡å‡†
            """)
        
        with col3:
            st.markdown("#### ğŸ›£ï¸ Hinge Loss")
            st.info("""
            **ç‰¹ç‚¹**:
            - âœ… f(x)>1æ—¶Loss=0
            - âœ… ä¸å…³å¿ƒ"å·²ç»å¤Ÿå¥½"çš„ç‚¹
            - âš ï¸ ä¸å¯å¾®ï¼ˆåœ¨f(x)=1å¤„ï¼‰
            - ğŸ¯ SVMçš„é€‰æ‹©
            """)
        
        # æ¢¯åº¦å¯¹æ¯”
        st.markdown("### ğŸ“Š æ¢¯åº¦å¯¹æ¯”")
        
        # è®¡ç®—æ¢¯åº¦
        dx = f_x[1] - f_x[0]
        mse_grad = np.gradient(mse_loss, dx)
        ce_grad = np.gradient(ce_loss, dx)
        hinge_grad = np.gradient(hinge_loss, dx)
        
        fig2 = go.Figure()
        
        fig2.add_trace(go.Scatter(x=f_x, y=mse_grad, mode='lines',
                                  name='MSEæ¢¯åº¦', line=dict(color='blue', width=2)))
        fig2.add_trace(go.Scatter(x=f_x, y=ce_grad, mode='lines',
                                  name='CEæ¢¯åº¦', line=dict(color='red', width=2)))
        fig2.add_trace(go.Scatter(x=f_x, y=hinge_grad, mode='lines',
                                  name='Hingeæ¢¯åº¦', line=dict(color='green', width=2)))
        
        fig2.update_layout(
            title="æŸå¤±å‡½æ•°æ¢¯åº¦å¯¹æ¯”",
            xaxis_title="f(x)",
            yaxis_title="âˆ‚Loss/âˆ‚f(x)",
            height=400
        )
        
        st.plotly_chart(fig2, use_container_width=True)
        
        st.info(r"""
        **æ¢¯åº¦çš„å«ä¹‰**:
        
        1. **MSEæ¢¯åº¦** ğŸ“ˆ
           - çº¿æ€§å¢é•¿ï¼š$\frac{\partial}{\partial f}[(f-y)^2] = 2(f-y)$
           - è¿œç¦»æ ‡ç­¾æ—¶æ¢¯åº¦å¾ˆå¤§
           - å¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®š
        
        2. **Cross-Entropyæ¢¯åº¦** ğŸ¯
           - è‡ªé€‚åº”ï¼šé”™è¯¯æ—¶æ¢¯åº¦å¤§ï¼Œæ­£ç¡®æ—¶æ¢¯åº¦å°
           - $\frac{\partial CE}{\partial f} = \sigma(f) - y$
           - æä¾›æŒç»­ä½†åˆç†çš„ä¼˜åŒ–ä¿¡å·
        
        3. **Hingeæ¢¯åº¦** âš¡
           - é˜¶è·ƒå‡½æ•°ï¼šè¦ä¹ˆ-1è¦ä¹ˆ0
           - f(x)>1æ—¶æ¢¯åº¦=0ï¼ˆä¸å†ä¼˜åŒ–ï¼‰
           - èŠ‚çœè®¡ç®—ï¼Œä½†å¯èƒ½é”™è¿‡è¿›ä¸€æ­¥ä¼˜åŒ–
        """)

    
    @staticmethod
    def _render_boundary_evolution():
        """å†³ç­–è¾¹ç•Œæ¼”åŒ–"""
        st.markdown("### ğŸ¬ å†³ç­–è¾¹ç•Œçš„è®­ç»ƒè¿‡ç¨‹")
        
        st.markdown(r"""
        **è§‚å¯Ÿ**: ä¸‰ç§æ–¹æ³•å¦‚ä½•ä»éšæœºåˆå§‹åŒ–é€æ­¥å­¦ä¹ åˆ°å†³ç­–è¾¹ç•Œ
        """)
        
        with st.sidebar:
            st.markdown("#### å‚æ•°è®¾ç½®")
            n_samples = st.slider("æ ·æœ¬æ•°é‡", 50, 200, 100, 10)
            animation_steps = st.slider("æ˜¾ç¤ºçš„è®­ç»ƒæ­¥æ•°", 5, 20, 10, 1)
        
        X, y = InteractiveClassificationOptimization._generate_binary_data(n_samples)
        y_binary = (y + 1) // 2
        
        # ä¸ºäº†æ¼”ç¤ºæ¼”åŒ–ï¼Œæˆ‘ä»¬è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„å‚æ•°
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šå±•ç¤ºæœ€ç»ˆç»“æœçš„ä¸åŒé˜¶æ®µ
        st.info("ğŸ’¡ æœ¬æ¼”ç¤ºå±•ç¤ºä¸‰ç§æ–¹æ³•çš„æœ€ç»ˆå†³ç­–è¾¹ç•Œå¯¹æ¯”")
        
        # è®­ç»ƒä¸‰ç§æ¨¡å‹
        lr_model = LinearRegression().fit(X, y)
        log_model = LogisticRegression(max_iter=1000).fit(X, y_binary)
        svm_model = SVC(kernel='linear', C=1.0).fit(X, y)
        
        # åˆ›å»ºå¯¹æ¯”å›¾
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=(
                "æ•°æ®åˆ†å¸ƒ",
                "æœ€å°äºŒä¹˜æ³•",
                "æœ€å¤§ä¼¼ç„¶ä¼°è®¡",
                "SVM"
            )
        )
        
        # å‡†å¤‡ç½‘æ ¼
        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                             np.linspace(y_min, y_max, 100))
        
        # å­å›¾1: åŸå§‹æ•°æ®
        for label in [-1, 1]:
            mask = y == label
            fig.add_trace(
                go.Scatter(
                    x=X[mask, 0],
                    y=X[mask, 1],
                    mode='markers',
                    name=f'Class {label}',
                    marker=dict(
                        size=8,
                        color='blue' if label == -1 else 'red'
                    ),
                    showlegend=True
                ),
                row=1, col=1
            )
        
        # å­å›¾2-4: ä¸‰ç§æ–¹æ³•çš„å†³ç­–è¾¹ç•Œ
        models_info = [
            (lr_model, 1, 2, "LSE"),
            (log_model, 2, 1, "MLE"),
            (svm_model, 2, 2, "SVM")
        ]
        
        for model, row, col, name in models_info:
            # é¢„æµ‹
            if name == "LSE":
                Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
            elif name == "MLE":
                Z = 2 * model.predict(np.c_[xx.ravel(), yy.ravel()]) - 1
            else:  # SVM
                Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
            
            Z = Z.reshape(xx.shape)
            
            # å†³ç­–è¾¹ç•ŒèƒŒæ™¯
            fig.add_trace(
                go.Contour(
                    x=xx[0],
                    y=yy[:, 0],
                    z=Z,
                    colorscale=[[0, 'lightblue'], [1, 'lightcoral']],
                    showscale=False,
                    opacity=0.3,
                    contours=dict(start=-1, end=1, size=2),
                    hoverinfo='skip'
                ),
                row=row, col=col
            )
            
            # æ•°æ®ç‚¹
            for label in [-1, 1]:
                mask = y == label
                fig.add_trace(
                    go.Scatter(
                        x=X[mask, 0],
                        y=X[mask, 1],
                        mode='markers',
                        marker=dict(
                            size=8,
                            color='blue' if label == -1 else 'red'
                        ),
                        showlegend=False
                    ),
                    row=row, col=col
                )
            
            # SVMçš„æ”¯æŒå‘é‡
            if name == "SVM":
                sv_mask = np.zeros(len(X), dtype=bool)
                sv_mask[model.support_] = True
                fig.add_trace(
                    go.Scatter(
                        x=X[sv_mask, 0],
                        y=X[sv_mask, 1],
                        mode='markers',
                        marker=dict(
                            size=12,
                            color='yellow',
                            symbol='circle-open',
                            line=dict(width=3, color='black')
                        ),
                        showlegend=False
                    ),
                    row=row, col=col
                )
        
        fig.update_layout(height=700, showlegend=True)
        st.plotly_chart(fig, use_container_width=True)
        
        # æ”¶æ•›ç‰¹æ€§å¯¹æ¯”
        st.markdown("### ğŸ“ˆ æ”¶æ•›ç‰¹æ€§å¯¹æ¯”")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("#### æœ€å°äºŒä¹˜æ³•")
            st.info("""
            **æ”¶æ•›é€Ÿåº¦**: âš¡ æœ€å¿«
            - é—­å¼è§£ï¼š$(X^TX)^{-1}X^Ty$
            - ä¸€æ­¥åˆ°ä½
            - ä½†ç»“æœå¯èƒ½ä¸ç†æƒ³
            """)
        
        with col2:
            st.markdown("#### æœ€å¤§ä¼¼ç„¶ä¼°è®¡")
            st.info("""
            **æ”¶æ•›é€Ÿåº¦**: ğŸ¢ è¾ƒæ…¢
            - éœ€è¦è¿­ä»£ä¼˜åŒ–
            - æ¢¯åº¦ä¸‹é™/Newtonæ³•
            - é€šå¸¸å‡ ååˆ°å‡ ç™¾æ¬¡è¿­ä»£
            """)
        
        with col3:
            st.markdown("#### SVM")
            st.info("""
            **æ”¶æ•›é€Ÿåº¦**: ğŸš€ ä¸­ç­‰
            - äºŒæ¬¡è§„åˆ’é—®é¢˜
            - SMOç®—æ³•é«˜æ•ˆ
            - åªéœ€ä¼˜åŒ–æ”¯æŒå‘é‡
            """)
        
        st.success("""
        **è®­ç»ƒæ•ˆç‡å¯¹æ¯”**:
        
        - **LSE**: è®¡ç®—æœ€å¿«ï¼Œä½†åˆ†ç±»æ•ˆæœå·®
        - **MLE**: å¹³è¡¡æ€§èƒ½ä¸æ•ˆç‡ï¼Œæœ€å¸¸ç”¨
        - **SVM**: åœ¨ä¸­å°è§„æ¨¡æ•°æ®ä¸Šå¾ˆé«˜æ•ˆï¼Œä½†å¤§è§„æ¨¡æ•°æ®è¾ƒæ…¢
        """)
    
    @staticmethod
    def _render_practical_case():
        """å®æˆ˜æ¡ˆä¾‹"""
        st.markdown("### ğŸ® å®æˆ˜æ¡ˆä¾‹ï¼šäº¤äº’å¼å®éªŒ")
        
        st.markdown("""
        **æ¢ç´¢ç©ºé—´**: è°ƒæ•´æ•°æ®åˆ†å¸ƒï¼Œè§‚å¯Ÿä¸‰ç§æ–¹æ³•çš„è¡¨ç°
        """)
        
        with st.sidebar:
            st.markdown("#### æ•°æ®ç”Ÿæˆ")
            n_samples = st.slider("æ ·æœ¬æ•°é‡", 50, 300, 100, 10)
            noise_level = st.slider("å™ªå£°æ°´å¹³", 0.0, 0.5, 0.1, 0.05)
            n_outliers = st.slider("ç¦»ç¾¤ç‚¹æ•°é‡", 0, 20, 0, 1)
            separability = st.slider("å¯åˆ†æ€§", 0.5, 3.0, 1.5, 0.1)
            
            st.markdown("#### æ¨¡å‹é€‰æ‹©")
            show_lse = st.checkbox("æœ€å°äºŒä¹˜æ³•", value=True)
            show_mle = st.checkbox("æœ€å¤§ä¼¼ç„¶ä¼°è®¡", value=True)
            show_svm = st.checkbox("SVM", value=True)
            
            if show_svm:
                svm_c = st.slider("SVMçš„Cå‚æ•°", 0.1, 10.0, 1.0, 0.1)
        
        # ç”Ÿæˆæ•°æ®
        np.random.seed(42)
        
        # ä½¿ç”¨make_blobsç”Ÿæˆæ›´å¯æ§çš„æ•°æ®
        from sklearn.datasets import make_blobs
        X, y = make_blobs(
            n_samples=n_samples,
            centers=[[-separability, -separability], [separability, separability]],
            cluster_std=1.0 + noise_level * 2,
            random_state=42
        )
        y = 2 * y - 1  # è½¬æ¢ä¸º{-1, 1}
        
        # æ·»åŠ ç¦»ç¾¤ç‚¹
        if n_outliers > 0:
            outlier_indices = np.random.choice(len(X), n_outliers, replace=False)
            y[outlier_indices] = -y[outlier_indices]
        
        y_binary = (y + 1) // 2
        
        # è®­ç»ƒæ¨¡å‹
        models = {}
        if show_lse:
            models['LSE'] = LinearRegression().fit(X, y)
        if show_mle:
            models['MLE'] = LogisticRegression().fit(X, y_binary)
        if show_svm:
            models['SVM'] = SVC(kernel='linear', C=svm_c).fit(X, y)
        
        # å¯è§†åŒ–
        fig = go.Figure()
        
        # ç½‘æ ¼
        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                             np.linspace(y_min, y_max, 100))
        
        # ç»˜åˆ¶æ¯ä¸ªæ¨¡å‹çš„å†³ç­–è¾¹ç•Œ
        colors_map = {'LSE': 'blue', 'MLE': 'green', 'SVM': 'purple'}
        
        for name, model in models.items():
            if name == "LSE":
                decision = model.predict(np.c_[xx.ravel(), yy.ravel()])
            elif name == "MLE":
                decision = model.decision_function(np.c_[xx.ravel(), yy.ravel()])
            else:  # SVM
                decision = model.decision_function(np.c_[xx.ravel(), yy.ravel()])
            
            decision = decision.reshape(xx.shape)
            
            # åªç”»å†³ç­–è¾¹ç•Œçº¿
            fig.add_trace(
                go.Contour(
                    x=xx[0],
                    y=yy[:, 0],
                    z=decision,
                    showscale=False,
                    contours=dict(
                        start=0,
                        end=0,
                        coloring='lines'
                    ),
                    line=dict(color=colors_map[name], width=3),
                    name=name
                )
            )
        
        # æ•°æ®ç‚¹
        for label in [-1, 1]:
            mask = y == label
            fig.add_trace(
                go.Scatter(
                    x=X[mask, 0],
                    y=X[mask, 1],
                    mode='markers',
                    name=f'Class {label}',
                    marker=dict(
                        size=8,
                        color='lightblue' if label == -1 else 'lightcoral',
                        line=dict(width=1, color='darkblue' if label == -1 else 'darkred')
                    )
                )
            )
        
        fig.update_layout(
            title="ä¸‰ç§æ–¹æ³•çš„å†³ç­–è¾¹ç•Œå¯¹æ¯”",
            xaxis_title="Feature 1",
            yaxis_title="Feature 2",
            height=600,
            showlegend=True
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # æ€§èƒ½å¯¹æ¯”
        st.markdown("### ğŸ“Š æ€§èƒ½å¯¹æ¯”")
        
        results = []
        for name, model in models.items():
            if name == "LSE":
                y_pred = (model.predict(X) > 0).astype(int)
                acc = np.mean((y_pred == 1) == (y == 1))
            elif name == "MLE":
                acc = model.score(X, y_binary)
            else:  # SVM
                acc = model.score(X, y)
            
            results.append({'æ–¹æ³•': name, 'å‡†ç¡®ç‡': f"{acc:.1%}"})
        
        import pandas as pd
        df_results = pd.DataFrame(results)
        st.dataframe(df_results, use_container_width=True)
        
        st.success("""
        **å®éªŒå»ºè®®**:
        
        1. **è°ƒæ•´å¯åˆ†æ€§**: è§‚å¯Ÿæ•°æ®è¶Šéš¾åˆ†æ—¶ï¼Œä¸‰ç§æ–¹æ³•çš„å·®å¼‚
        2. **æ·»åŠ ç¦»ç¾¤ç‚¹**: LSEå—å½±å“æœ€å¤§ï¼ŒSVMæœ€é²æ£’
        3. **å¢åŠ å™ªå£°**: è§‚å¯Ÿå“ªç§æ–¹æ³•æ›´ç¨³å®š
        4. **è°ƒæ•´SVMçš„C**: å¤§Cè¿½æ±‚å‡†ç¡®ï¼Œå°Cè¿½æ±‚å¤§é—´éš”
        
        **ç»“è®º**: 
        - ç®€å•é—®é¢˜ï¼šä¸‰ç§æ–¹æ³•éƒ½å¯ä»¥
        - æœ‰å™ªå£°/ç¦»ç¾¤ç‚¹ï¼šSVM > MLE > LSE
        - éœ€è¦æ¦‚ç‡è¾“å‡ºï¼šMLEæœ€ä½³
        - è¿½æ±‚é€Ÿåº¦ï¼šLSEæœ€å¿«ï¼ˆä½†ä¸æ¨èåˆ†ç±»ï¼‰
        """)


# æ³¨å†Œåˆ°__all__
__all__ = ['InteractiveClassificationOptimization']

